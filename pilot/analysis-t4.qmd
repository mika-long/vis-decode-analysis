---
title: "Analysis - Task 4"
format: 
  html: 
    code-fold: false
    reference-location: margin
    df-print: paged
    toc: true
    code-overflow: wrap
---

```{r}
#| echo: false
#| output: false
#| label: setup

library(tidyverse)
library(ggplot2)
library(sgt)
library(numDeriv)
library(ggdist)
# setting the theme 
theme_set(theme_minimal())
# model
library(brms)
# plot results 
library(tidybayes)
```

# Set up

Read in data 

```{r}
#| label: read-in-data
#| code-fold: true

task_df <- read_rds("task.rds")
participants <- read_rds("participants.rds")
```

```{r}
#| label: define-function
#| code-fold: true

# origin is top left  
data_to_pixel_y <- function(data_y) {
  return(-395 * data_y + 410)
}
data_to_pixel_x <- function(data_x) {
  return (53.5 * data_x + 317.5)
}

# origin is bottom left 
pixel_to_phy_x <- function(pixel, pxMM){
  (pixel - 50) / pxMM
}
pixel_to_phy_y <- function(pixel, pxMM){
  (410 - pixel) / pxMM
}

# return visual angle in degrees and not radian
vis_angle <- function(size, distance){
  return(2 * atan(size / (2 * distance)) * 180 / pi)
}

# tolerance for numerical precision 
tolerance <- 1e-10
```

# Task 4 --- find highest slope 

```{r}
#| label: get task 4 data 

data_to_screen_slope <- function(k){
  return(k * 395 / 53.5)
}

task4_df <- task_df %>% filter(task == "task4") %>% 
  select(-slider.x, -slider.y) %>% 
  mutate(data.select.slope = dsgt(data.select.x, param.mu, param.sigma, param.lambda, param.p, param.q, mean.cent=FALSE), 
         data.ans.slope = dsgt(param.mu, param.mu, param.sigma, param.lambda, param.p, param.q, mean.cent=FALSE)) %>% 
  right_join(participants, by = join_by(participantId)) %>% 
  mutate(phy.select.x = pixel_to_phy_x(pixel.select.x, pixelToMM), 
         phy.select.y = pixel_to_phy_y(pixel.select.y, pixelToMM),
         va.select.x = vis_angle(phy.select.x, dist_to_screen), 
         va.select.y = vis_angle(phy.select.y, dist_to_screen)) %>%
  mutate(data.ans.x = param.mu, 
         data.ans.y = 1 / 2 * (psgt(data.ans.x + tolerance, param.mu, param.sigma, param.lambda, param.p, param.q, mean.cent = FALSE) +  
                                            psgt(data.ans.x - tolerance, param.mu, param.sigma, param.lambda, param.p, param.q, mean.cent = FALSE))) %>%
  mutate(pixel.ans.x = data_to_pixel_x(data.ans.x), 
         pixel.ans.y = data_to_pixel_y(data.ans.y)) %>% 
  mutate(phy.ans.x = pixel_to_phy_x(pixel.ans.x, pixelToMM), 
         phy.ans.y = pixel_to_phy_y(pixel.ans.y, pixelToMM)) %>% 
  mutate(va.ans.x = vis_angle(phy.ans.x, dist_to_screen), 
         va.ans.y = vis_angle(phy.ans.y, dist_to_screen)) 

```

Check relations 

```{r}
task4_df %>% ggplot(aes(x = data_to_screen_slope(data.select.slope) - data_to_screen_slope(data.ans.slope))) + 
  geom_dots()


task4_df %>% ggplot(aes(x = va.ans.x - va.select.x)) + geom_dots()
task4_df %>% ggplot(aes(x = va.ans.y - va.select.y)) + geom_dots()
task4_df %>% ggplot(aes(x = atan(va.ans.y / va.ans.x) * 180 / pi)) + geom_dots()
task4_df %>% ggplot(aes(x = va.ans.y / va.ans.x, y = data.ans.slope)) + 
  geom_point() + coord_equal()

task4_df %>% ggplot(aes(x = data.select.slope - data.ans.slope)) + 
  geom_dots()

task4_df %>% filter(data.select.slope - data.ans.slope == 0)

task4_df %>% ggplot(aes(x = atan(data.select.slope) * 180 / pi - atan(data.ans.slope) * 180 / pi)) + 
  geom_dots()



task4_df %>% ggplot(aes(x = atan(data_to_screen_slope(data.select.slope)) * 180 / pi - atan(data_to_screen_slope(data.ans.slope)) * 180 / pi)) + 
  # geom_dots()
  stat_ecdf()
# maybe try to fit a model here 
```

If we map the mathematical slope to the actual slope, this is what we get: 

- y axis range [0,1] correspond to 395 px -> 395px / unit 
- x axis range [-5, 5] correspond to 535 px -> 53.5 px / unit 

```{r}
task4_df %>% ggplot(aes(x = data_to_screen_slope(data.select.slope), 
                        y = data_to_screen_slope(data.ans.slope))) + 
  geom_point(alpha = 0.5) + 
  coord_equal()

task4_df %>% ggplot(aes(x = data_to_screen_slope(data.select.slope) - data_to_screen_slope(data.ans.slope))) + 
  geom_dots()
```

Let's first see the distribution of signed error: 

```{r}
task4_df %>% ggplot(aes(x = data.select.slope - data.ans.slope)) + 
  geom_dots()

task4_df %>% ggplot(aes(y = data.select.slope - data.ans.slope, x = dist_to_screen)) + 
  geom_point(alpha = 0.5)
```

Let's see if there's any obvious relation between signed error and parameters of the distribution: 

```{r}
#| layout-ncol: 2
#| code-fold: true 
#| output: false 

task4_df %>% ggplot(aes(y = data.select.slope - data.ans.slope, x = dist_to_screen)) + 
  geom_point()

task4_df %>% ggplot(aes(y = data.select.slope - data.ans.slope, x = param.mu)) + 
  geom_point()

task4_df %>% ggplot(aes(y = data.select.slope - data.ans.slope, x = param.sigma)) + 
  geom_point()

task4_df %>% ggplot(aes(y = data.select.slope - data.ans.slope, x = param.lambda)) + 
  geom_point()

task4_df %>% ggplot(aes(y = data.select.slope - data.ans.slope, x = param.p)) + 
  geom_point()

task4_df %>% ggplot(aes(y = data.select.slope - data.ans.slope, x = param.q)) + 
  geom_point()

task4_df %>% ggplot(aes(x = data.select.slope - data.ans.slope)) + 
  geom_dots()
```

## Exponential Model 

Math model: 

$$\begin{align*}
\text{error_i} &\sim \text{Exponential}(\lambda_{\text{PID}[i]}) \\ 
\log(\lambda_j) &\sim \mathcal{N}(\mu_\lambda, \sigma_\lambda) \\ 
\mu_\lambda &\sim \mathcal{N}(0, 1) \\ 
\sigma_\lambda &\sim \text{Half-Cauchy}(0, 1) 
\end{align*}$$

Formula: 

```{r}
f <- bf(error ~ 0,
        mu ~ (1 | participantId),  
        family = exponential())

# mu has log-link, so we don't pose any bounds on it 
p <- c(
  prior(normal(0, 1), class = Intercept), 
  prior(normal(0, 1), class = sd, group = participantId, lb = 0)
)
```

```{r}
#| eval: false 
#| echo: false 

task4_df %>% mutate(error = abs(data_to_screen_slope(data.select.slope) - data_to_screen_slope(data.ans.slope))) %>% 
  get_prior(f, data = .)

task2_df %>% mutate(error.x = va.select.x - va.ans.x) %>% 
  make_stancode(f, data = ., prior = p)
```

Fir the model: 

```{r}
#| output: false 
#| label: fit exponential 

model.exponential <- task4_df %>% 
  mutate(error = abs(data_to_screen_slope(data.ans.slope) - data_to_screen_slope(data.select.slope))) %>% 
  mutate(error = ifelse(abs(error) < tolerance, tolerance, error)) %>% # brms need rsp > 0 
  brm(formula = f, 
      data = ., 
      prior = p, 
      chains = 4, 
      file = "models/task4.exponential", 
      file_refit = "on_change",
      save_pars = save_pars(all = TRUE), 
      iter = 6000
  )
```

Check fit: 

```{r}
summary(model.exponential)
plot(model.exponential)
pp_check(model.exponential, ndraws = 100)
pp_check(model.exponential, ndraws = 100, type = "pit_ecdf")
```

```{r}
model.exponential %>% get_variables()

model.exponential %>% spread_draws(b_Intercept, sd_participantId__Intercept) %>% 
  mutate(lambda = exp(b_Intercept))  %>% 
  pivot_longer(5:6)  %>% 
  ggplot(aes(x = value, y = name)) + 
  stat_halfeye()
```

Overlay plot: 

```{r}
prediction <- task4_df %>% 
  mutate(error = abs(data_to_screen_slope(data.ans.slope) - data_to_screen_slope(data.select.slope))) %>% 
  mutate(error = ifelse(abs(error) < tolerance, tolerance, error)) %>% 
  add_predicted_draws(model.exponential, re_formula = NA)

prediction %>% ggplot() + 
  stat_slab(aes(x = .prediction), 
            fill = "skyblue", alpha = 0.8)  + 
  geom_dots(data = task4_df, aes(x = data_to_screen_slope(data.ans.slope) - data_to_screen_slope(data.select.slope)))
```

```{r}
task4_df %>% modelr::data_grid(error = 0) %>% 
  add_predicted_draws(model.exponential, ndraws = 100, re_formula = NA) %>% 
  ggplot() + 
  stat_slab(aes(x = .prediction), 
            fill = "lightblue", alpha = 1) + 
  geom_dots(data = task4_df, aes(x = data_to_screen_slope(data.ans.slope) - data_to_screen_slope(data.select.slope))) 
```

## Lomax Model 

Lomax is Pareto Type II distribution. We had similar models for task 2. 

Note that the Half-Cauchy prior for hyperpriors led to divergent transitions, so we switched to truncated normal. 

```{r}
lomax_family <- custom_family(
  "lomax",
  dpars = c("mu", "lambda", "alpha"),    # includes mu as required
  links = c("identity", "log", "log"),   # appropriate links
  lb = c(-Inf, 0, 0),                    # appropriate bounds
  type = "real"
)

stan_funs <- "
  real lomax_lpdf(real y, real mu, real lambda, real alpha) {
    return pareto_type_2_lpdf(y | 0, lambda, alpha);  # mu is ignored
  }
  
  real lomax_rng(real mu, real lambda, real alpha) {
    return pareto_type_2_rng(0, lambda, alpha);  # mu is ignored
  }
"
```

```{r}
# Define the formula for the model
f <- bf(
  error ~ 0,  
  mu ~ 0, 
  alpha ~ (1 | participantId), 
  lambda ~ (1 | participantId)  
)

p <- c(
    prior(normal(0, 1), class = Intercept, dpar = alpha),
    prior(normal(0, 1), class = sd, group = participantId, dpar = alpha, lb = 0),
    prior(normal(0, 1), class = Intercept, dpar = lambda), 
    prior(normal(0, 1), class = sd, group = participantId, dpar = lambda, lb = 0)
  )
```

```{r}
#| eval: false 
#| echo: false 

task4_df %>%  mutate(error = abs(data_to_screen_slope(data.select.slope) - data_to_screen_slope(data.ans.slope))) %>%
  mutate(error = ifelse(error < tolerance, tolerance, error)) %>% 
  get_prior(formula = f, family = lomax_family)

task4_df %>% mutate(error = abs(data_to_screen_slope(data.select.slope) - data_to_screen_slope(data.ans.slope)) + tolerance) %>% 
  make_stancode(formula = f, family = lomax_family, prior = p)
```

```{r}
#| output: false 
#| label: fit lomax 

model.lomax <- task4_df %>% mutate(error = abs(data_to_screen_slope(data.select.slope) - data_to_screen_slope(data.ans.slope))) %>% 
  mutate(error = ifelse(error < tolerance, tolerance, error)) %>% 
  brm(
    formula = f,
    data = .,
    family = lomax_family,
    prior = p,
    stanvars = stanvar(scode = stan_funs, block = "functions"),
    chains = 4,
    # cores = 4, 
    file = "models/task4.lomax", 
    control = list(adapt_delta = 0.99), 
    iter = 4000, 
    save_pars = save_pars(all = TRUE)
  )
```

Check fit: 

```{r}
# pairs(model.lomax)
summary(model.lomax)
plot(model.lomax)
```

Let's check the posterior of alpha and lambda: 

```{r}
model.lomax %>% spread_draws(`^b_.*`, regex = TRUE) %>% 
  mutate(b_alpha = exp(b_alpha_Intercept), b_lambda = exp(b_lambda_Intercept)) %>% 
  pivot_longer(6:7) %>% 
  ggplot(aes(x = value, y = name)) + 
  stat_halfeye() + 
  facet_wrap(~name, scales = "free") + 
  geom_vline(xintercept = 1e-10, linetype = "dashed", color = "gray")
```

Define custom functions for `pp_check` and `loo`: 

```{r}
expose_functions(model.lomax, vectorize = TRUE)

# Define the posterior_predict function in R as per vignette
posterior_predict_lomax <- function(i, draws, ...) {
  alpha <- draws$dpars$alpha[i]
  lambda <- draws$dpars$lambda[i]
  # Use Stan's rng function indirectly via brms
  lomax_rng(0, lambda, alpha)
}

log_lik_lomax <- function(i, prep){
  alpha <- brms::get_dpar(prep, "alpha", i = i)
  lambda <- brms::get_dpar(prep, "lambda", i = i)
  y <- prep$data$Y[i]
  lomax_lpdf(y, 0, lambda, alpha)
}

pp_check(model.lomax, ndraws = 100) 
pp_check(model.lomax, ndraws = 100, type = "pit_ecdf")
```

Overlay plot: 

```{r}
prediction <- task4_df %>% 
  mutate(error = abs(data_to_screen_slope(data.ans.slope) - data_to_screen_slope(data.select.slope))) %>% 
  add_predicted_draws(model.lomax, ndraws = 100)

prediction %>% ggplot() + 
  stat_slab(aes(x = .prediction), 
            fill = "lightblue", alpha = 1) + 
  geom_dots(data = task4_df, aes(x = data_to_screen_slope(data.ans.slope) - data_to_screen_slope(data.select.slope)))
```

```{r}
# huh something is a bit wrong with its add_predicted_draws ... 
task4_df %>% modelr::data_grid(error = 0, participantId = unique(participantId)) %>% 
  add_predicted_draws(model.lomax, ndraws = 100, re_formula = NA)
```


## Weibull distribution 

- [wikipedia](https://en.wikipedia.org/wiki/Weibull_distribution) 
- [stan](https://mc-stan.org/docs/functions-reference/positive_continuous_distributions.html#weibull-distribution) 
- it's also implemented in brms! So no need for a custom function. 

```{r}
f <- bf(
  error ~ 0,  
  mu ~ (1 | participantId), # log link 
  shape ~ (1 | participantId), # log link 
  family = weibull
)

p <- c(
    prior(normal(0, 1), class = Intercept),
    prior(normal(0, 1), class = sd, group = participantId, lb = 0),
    prior(normal(0, 1), class = Intercept, dpar = shape), 
    prior(normal(0, 1), class = sd, group = participantId, dpar = shape, lb = 0)
  )
```

```{r}
#| eval: false 
#| echo: false 

task4_df %>%  mutate(error = abs(data_to_screen_slope(data.select.slope) - data_to_screen_slope(data.ans.slope))) %>%
  mutate(error = ifelse(error < tolerance, tolerance, error)) %>% 
  get_prior(formula = f)

task4_df %>% mutate(error = abs(data_to_screen_slope(data.select.slope) - data_to_screen_slope(data.ans.slope)) + tolerance) %>% 
  make_stancode(formula = f, prior = p)
```

Fit the model: 

```{r}
#| output: false 
#| label: fit weibull 

model.weibull <- task4_df %>% 
  mutate(error = abs(data_to_screen_slope(data.ans.slope) - data_to_screen_slope(data.select.slope))) %>% 
  mutate(error = ifelse(error < tolerance, tolerance, error)) %>% # brms needs value to be > 0  
  brm(formula = f, 
      data = ., 
      prior = p, 
      chains = 4, 
      cores = 4, 
      file = "models/task4.weibull", 
      file_refit = "on_change",
      save_pars = save_pars(all = TRUE), 
      iter = 6000 
  )
```

Check fit and posterior: 

```{r}
summary(model.weibull)
plot(model.weibull)
pp_check(model.weibull, ndraws = 100)
pp_check(model.weibull, ndraws = 100, type = "pit_ecdf")
```

```{r}
model.weibull %>% get_variables()

model.weibull %>% spread_draws(b_Intercept, b_shape_Intercept) %>% 
  mutate(mu = exp(b_Intercept), shape = exp(b_shape_Intercept)) %>% 
  pivot_longer(6:7) %>% 
  ggplot(aes(x = value, y = name)) + 
  stat_halfeye()
```

Overlay plot: 

```{r}
#| code-fold: true 
#| layout-ncol: 3 
# prediction <- task4_df %>% 
#   mutate(error = abs(data_to_screen_slope(data.ans.slope) - data_to_screen_slope(data.select.slope))) %>% 
#   add_predicted_draws(model.weibull, ndraws = 100)

task4_df %>% modelr::data_grid(error = 0) %>% 
  add_predicted_draws(model.weibull, re_formula = NA) %>% 
  ggplot() + 
  stat_slab(aes(x = .prediction), 
            fill = "lightblue", alpha = 1) + 
  geom_dots(data = task4_df, aes(x = data_to_screen_slope(data.ans.slope) - data_to_screen_slope(data.select.slope))) 

task4_df %>% modelr::data_grid(error = 0, participantId = unique(participantId)) %>% 
  add_predicted_draws(model.weibull, ndraws = 100) %>% 
  group_by(.draw) %>% 
  summarise(avg_pred = mean(.prediction)) %>% 
  ggplot() + 
  stat_slab(aes(x = avg_pred), 
            fill = "lightblue", alpha = 1) # + 
  geom_dots(data = task4_df, aes(x = data_to_screen_slope(data.ans.slope) - data_to_screen_slope(data.select.slope))) 
  
task4_df %>% modelr::data_grid(error = 0) %>% 
  add_predicted_draws(model.weibull, ndraws = 100, re_formula = NA) %>% 
  ggplot() + 
  stat_slab(aes(x = .prediction), 
            fill = "lightblue", alpha = 1) # + 
  geom_dots(data = task4_df, aes(x = data_to_screen_slope(data.ans.slope) - data_to_screen_slope(data.select.slope))) 

# prediction %>% ggplot() + 
#   stat_slab(aes(x = .prediction), 
#             fill = "lightblue", alpha = 1) + 
#   geom_dots(data = task4_df, aes(x = data_to_screen_slope(data.ans.slope) - data_to_screen_slope(data.select.slope))) + 
#   xlim(0, 10)
```

```{r}
task4_df %>% modelr::data_grid(error = 0) %>% 
  add_predicted_draws(model.weibull, re_formula = NA) %>% 
  ggplot() + 
  stat_slab(aes(x = .prediction), 
            fill = "lightblue", alpha = 1) + 
  geom_dots(data = task4_df, aes(x = data_to_screen_slope(data.ans.slope) - data_to_screen_slope(data.select.slope))) + 
  labs(y = "Probability", x = "Signed error") + 
  xlim(0, 5) + 
  theme_minimal(base_size = 8) -> p 

p
```

```{r}
#| echo: false 
#| eval: false 

ggsave("plots/task4.pdf", plot = p, height = 5, width = 5, unit = "cm", dpi = 300)
```


<!-- ## Gamma distribution  -->

<!-- ```{r} -->
<!-- f <- bf(error ~ 0, -->
<!--         mu ~ (1 | participantId),  -->
<!--         shape ~ (1 | participantId),  -->
<!--         family = Gamma()) -->

<!-- p <- c( -->
<!--   prior(normal(0, 1), class = Intercept),  -->
<!--   prior(normal(0, 1), class = sd, group = participantId, lb = 0),  -->
<!--   prior(normal(0, 1), class = Intercept, dpar = shape),  -->
<!--   prior(normal(0, 1), class = sd, group = participantId, dpar = shape, lb = 0) -->
<!-- ) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- #| echo: false  -->
<!-- #| eval: false  -->

<!-- task4_df %>%  -->
<!--   mutate(error = abs(data_to_screen_slope(data.ans.slope) - data_to_screen_slope(data.select.slope))) %>%  -->
<!--   get_prior(data = ., formula = f) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- #| output: false  -->
<!-- #| label: fit gamma  -->

<!-- model.gamma <- task4_df %>%  -->
<!--   mutate(error = abs(data_to_screen_slope(data.ans.slope) - data_to_screen_slope(data.select.slope))) %>%  -->
<!--   mutate(error = ifelse(error < tolerance, tolerance, error)) %>% # brms needs value to be > 0   -->
<!--   brm(formula = f,  -->
<!--       data = .,  -->
<!--       prior = p,  -->
<!--       chains = 4,  -->
<!--       cores = 4,  -->
<!--       file = "models/task4.gamma",  -->
<!--       file_refit = "on_change", -->
<!--       save_pars = save_pars(all = TRUE),  -->
<!--       control = list(adapt_delta = 0.99, max_treedepth = 15),  -->
<!--       iter = 6000 -->
<!--   ) -->
<!-- ``` -->

<!-- Alright the above still gives a lot of divergent transitions ...  -->

<!-- Check fit and posterior:  -->

<!-- ```{r} -->
<!-- summary(model.gamma) -->
<!-- plot(model.gamma) -->
<!-- pp_check(model.gamma, ndraws = 100) -->
<!-- pp_check(model.gamma, ndraws = 100, type = "pit_ecdf") -->
<!-- ``` -->

<!-- Overlay plot:  -->

<!-- ```{r} -->
<!-- prediction <- task4_df %>%  -->
<!--   mutate(error = abs(data_to_screen_slope(data.ans.slope) - data_to_screen_slope(data.select.slope))) %>%  -->
<!--   add_predicted_draws(model.gamma, ndraws = 100) -->

<!-- prediction %>% ggplot() +  -->
<!--   stat_slab(aes(x = .prediction),  -->
<!--             fill = "lightblue", alpha = 1) +  -->
<!--   geom_dots(data = task4_df, aes(x = data_to_screen_slope(data.ans.slope) - data_to_screen_slope(data.select.slope))) +  -->
<!--   xlim(0, 10) -->
<!-- ``` -->

## Log-Normal distribution 

```{r}
f <- bf(error ~ 0,
        mu ~ (1 | participantId), 
        sigma ~ (1 | participantId), 
        family = lognormal())

p <- c(
  prior(normal(0, 1), class = Intercept), 
  prior(normal(0, 1), class = sd, group = participantId, lb = 0), 
  prior(normal(0, 1), class = Intercept, dpar = sigma), 
  prior(normal(0, 1), class = sd, group = participantId, dpar = sigma, lb = 0)
)
``` 

```{r}
#| echo: false 
#| eval: false 

task4_df %>% 
  mutate(error = abs(data_to_screen_slope(data.ans.slope) - data_to_screen_slope(data.select.slope))) %>% 
  get_prior(data = ., formula = f)
```

```{r}
#| output: false 
#| label: fit lognormal 

model.lognormal <- task4_df %>% 
  mutate(error = abs(data_to_screen_slope(data.ans.slope) - data_to_screen_slope(data.select.slope))) %>% 
  mutate(error = ifelse(error < tolerance, tolerance, error)) %>% # brms needs value to be > 0  
  brm(formula = f, 
      data = ., 
      prior = p, 
      chains = 4, 
      # cores = 4, 
      file = "models/task4.lognormal", 
      file_refit = "on_change",
      save_pars = save_pars(all = TRUE), 
      control = list(adapt_delta = 0.99),
      iter = 4000 
  )
```

Check fit and posterior: 

```{r}
summary(model.lognormal)
plot(model.lognormal)
pp_check(model.lognormal, ndraws = 100)
pp_check(model.lognormal, ndraws = 100, type = "pit_ecdf")
```

Overlay plot: 

```{r}
prediction <- task4_df %>% 
  mutate(error = abs(data_to_screen_slope(data.ans.slope) - data_to_screen_slope(data.select.slope))) %>% 
  add_predicted_draws(model.lognormal, ndraws = 100)

prediction %>% ggplot() + 
  stat_slab(aes(x = .prediction), 
            fill = "lightblue", alpha = 1) + 
  geom_dots(data = task4_df, aes(x = data_to_screen_slope(data.ans.slope) - data_to_screen_slope(data.select.slope))) + 
  xlim(0, 10)
```

```{r}
task4_df %>% modelr::data_grid(error = 0) %>% 
  add_predicted_draws(model.lognormal, re_formula = NA, ndraws = 100) %>% 
  ggplot() + 
  stat_slab(aes(x = .prediction), 
            fill = "lightblue", alpha = 1) + 
  geom_dots(data = task4_df, aes(x = data_to_screen_slope(data.ans.slope) - data_to_screen_slope(data.select.slope)))
```


## Model Comparison

```{r}
loo(model.exponential, model.lomax, model.weibull, model.lognormal, moment_match = TRUE) # ignoring model.gamma for now cause it does not fit 
```

The weibull model performs the best.

```{r}
#| layout-ncol: 3

pp_check(model.exponential, ndraws = 100, type = "pit_ecdf")
pp_check(model.lomax, ndraws = 100, type = "pit_ecdf")
pp_check(model.weibull, ndraws = 100, type = "pit_ecdf")
# pp_check(model.gamma, ndraws = 100, type = "pit_ecdf")
pp_check(model.lognormal, ndraws = 100, type = "pit_ecdf")
```



