---
title: "Models - Task 2 - Find Highest Point on Curve"
format:
  html: 
    code-fold: false
    reference-location: margin
    df-print: paged
    toc: true
    code-overflow: wrap
---

```{r}
#| echo: false
#| output: false
#| label: setup

library(tidyverse)
library(ggplot2)
library(sgt)
library(numDeriv)
library(ggdist)
# setting the theme 
theme_set(theme_minimal())
# model
library(brms)
# plot results 
library(tidybayes)
```

# Set up 

read in data and write functions for processing: 

```{r}
#| label: read-in-data
#| code-fold: true

df <- read.csv("vis-decode-slider_all_tidy.csv") %>% as_tibble(.)

# filter 
ids <- df %>% count(participantId) %>% filter(n == 492) %>% pull(participantId) 
df <- df %>% filter(participantId %in% ids)

# create a separate dataframe for just test related trials 
task_df <- df %>% filter(grepl("task", trialId) & grepl("test", trialId) ) %>% 
    select(participantId, trialId, responseId, answer) %>% 
    mutate(answer = as.numeric(answer)) %>% 
    pivot_wider(names_from = responseId, values_from = answer, names_repair = "universal") %>% 
  separate_wider_delim(trialId, delim = "_", names = c("task", "type", "id")) %>% 
  select(-type) %>% 
  rename(data.select.x = location.x, 
         data.select.y = location.y,
         pixel.select.x = pixel.x, 
         pixel.select.y = pixel.y)

# create a dataframe for single participant (Sheng only) 
not_sheng <- c("5f37a06e-50e4-4489-948f-c4f25bd38d17", "85349f2b-c75a-46ff-8f80-fafc92da11a7")
single_pid_df <- task_df %>% filter(!participantId %in% not_sheng)
```

```{r}
#| label: define-function
#| code-fold: true

# origin is top left  
data_to_pixel_y <- function(data_y) {
  return(-395 * data_y + 410)
}
data_to_pixel_x <- function(data_x) {
  return (53.5 * data_x + 317.5)
}

# origin is bottom left 
pixel_to_phy_x <- function(pixel, pxMM){
  (pixel - 50) / pxMM
}
pixel_to_phy_y <- function(pixel, pxMM){
  (410 - pixel) / pxMM
}

# return visual angle in degrees and not radian
vis_angle <- function(size, distance){
  return(2 * atan(size / (2 * distance)) * 180 / pi)
}

# return size given vis angle 
size <- function(va, distance){
  return(tan((va / (180 / pi)) / 2) * 2 * distance)
}

phy_to_pixel_y <- function(phy, pxMM){
  return(410 - phy * pxMM)
}

phy_to_pixel_x <- function(phy, pxMM){
  return(50 + phy * pxMM)
}

pixel_to_data_x <- function(pixel){
  return((pixel - 317.5)/53.5)
}

pixel_to_data_y <- function(pixel){
  return((410 - pixel)/395)
}

# tolerance for numerical precision 
tolerance <- 1e-10
```

```{r}
#| label: define-special-dfs
#| code-fold: true

p <- df %>% filter(participantId %in% ids) %>% 
  filter(grepl("pixelsPerMM", responseId) | grepl("prolificId", responseId)) %>% 
  select(participantId, responseId, answer) %>% 
  pivot_wider(names_from = responseId, values_from = answer) %>% 
  pull(participantId)

# custom dataframe 
pixel_to_mm <- data.frame(participantId = p, 
  pixelToMM = c(3.73, 3.27, 3.27, 5.03, 3.73, 3.25, 3.73, 3.27, 3.73, 3.27, 5.14, 3.30, 3.29)
)

vis_distance <- data.frame(participantId = p, 
                           dist_to_screen = c(426, 502, 500, 495, 485, 987, 635, 500, 479, 563, 449, 685, 462))

# combine 
participants <- pixel_to_mm %>% left_join(vis_distance, by = join_by(participantId))
```


# Task 2 -- Find highest point on curve 

First we get the data: 

```{r}
#| label: get task 2 data
#| code-fold: true 

task2_df <- single_pid_df %>% filter(task == "task2") %>% 
  select(-slider.x, -slider.y) %>% 
  mutate(data.ans.x = param.mu, 
         data.ans.y = dsgt(param.mu, param.mu, param.sigma, param.lambda, param.p, param.q, mean.cent = FALSE),
         # data.select.grad = numDeriv::grad(dsgt, data.select.x, mu = param.mu, sigma = param.sigma, lambda = param.lambda, p = param.p, q = param.q, mean.cent = FALSE), 
         # data.select.angle = atan(data.select.grad) * 180 / pi
         # this is the gradient of the left of the highest point 
         data.left.grad = numDeriv::grad(dsgt, param.mu - 1, mu = param.mu, sigma = param.sigma, lambda = param.lambda, p = param.p, q = param.q, mean.cent = FALSE), 
         data.right.grad = numDeriv::grad(dsgt, param.mu + 1, mu = param.mu, sigma = param.sigma, lambda = param.lambda, p = param.p, q = param.q, mean.cent = FALSE), 
         ) %>% 
  left_join(participants, by = join_by(participantId)) %>% 
  # calculate things related to participants' selection 
  mutate(phy.select.x = pixel_to_phy_x(pixel.select.x, pixelToMM), 
         phy.select.y = pixel_to_phy_y(pixel.select.y, pixelToMM),
         va.select.x = vis_angle(phy.select.x, dist_to_screen), 
         va.select.y = vis_angle(phy.select.y, dist_to_screen)) %>% 
  # calculate things related to answer 
  mutate(pixel.ans.x = data_to_pixel_x(data.ans.x), 
         pixel.ans.y = data_to_pixel_y(data.ans.y), 
         phy.ans.x = pixel_to_phy_x(pixel.ans.x, pixelToMM), 
         phy.ans.y = pixel_to_phy_y(pixel.ans.y, pixelToMM),
         va.ans.x = vis_angle(phy.ans.x, dist_to_screen),
         va.ans.y = vis_angle(phy.ans.y, dist_to_screen)) %>% 
  mutate(flat = (abs(data.left.grad) + abs(data.right.grad))/2)
```

Checking relations, focusing on the **y** axes: 

```{r}
#| layout-ncol: 2
#| code-fold: true

task2_df %>% ggplot(aes(y = phy.ans.y - phy.select.y, x = dist_to_screen)) + 
  geom_point()

task2_df %>% ggplot(aes(y = va.ans.y - va.select.y, x = dist_to_screen)) + 
  geom_point()

task2_df %>% ggplot(aes(x = va.ans.y - va.select.y)) + geom_dots()
task2_df %>% ggplot(aes(x = phy.ans.y - phy.select.y)) + geom_dots()
task2_df %>% ggplot(aes(x = (phy.ans.y - phy.select.y) / dist_to_screen)) + geom_dots()
```

Checking relations, ocusing on the **x** axes: 

```{r}
#| layout-ncol: 2
#| code-fold: true

library(RColorBrewer)

task2_df %>% ggplot(aes(x = data.ans.x - data.select.x)) + 
  geom_dots()

task2_df %>% ggplot(aes(x = va.select.x - va.ans.x)) + 
  geom_dots()

task2_df %>% ggplot(aes(x = (phy.ans.x - phy.select.x)/dist_to_screen)) + 
  geom_dots()

task2_df %>% ggplot(aes(x = va.select.x - va.ans.x)) + 
  geom_dots() + 
  facet_wrap(~participantId)

task2_df %>% ggplot(aes(y = va.select.x - va.ans.x, x = dist_to_screen)) + 
  geom_point(alpha = 0.5)

task2_df %>% ggplot(aes(y = va.select.x - va.ans.x, x = param.lambda)) + 
  geom_point(alpha = 0.5) + 
  labs(title = "Signed error on x-axes against skewness")
```

:::{.callout-note collapsed="true"}
Here's one way to approximate `param.p`: 

```{r}
#| code-fold: true 
#| layout-ncol: 2 
task2_df %>% ggplot(aes(y = va.select.x - va.ans.x, x = param.p, color = param.lambda)) + 
  geom_point() + 
  labs(title = "Signed error on x-axes against flat-top-ness") + 
  scale_color_gradient2(
    low = brewer.pal(11, "RdYlBu")[1],   # Red for negative
    mid = brewer.pal(11, "RdYlBu")[6],   # Yellow for zero
    high = brewer.pal(11, "RdYlBu")[11], # Blue for positive
    midpoint = 0
  )

task2_df %>% ggplot(aes(y = va.select.x - va.ans.x, x = flat)) + 
  geom_point(alpha = 0.5) + 
  labs(title = "Signed error on x-axes against flat-top-ness") + 
  scale_color_gradient2(
    low = brewer.pal(11, "RdYlBu")[1],   # Red for negative
    mid = brewer.pal(11, "RdYlBu")[6],   # Yellow for zero
    high = brewer.pal(11, "RdYlBu")[11], # Blue for positive
    midpoint = 0
  )
```
:::

## Task 2 - Vis Angle - error on Y 

Recall the trends: 

```{r}
#| code-fold: true 

task2_df %>% mutate(error.y = va.ans.y - va.select.y, error.x = va.ans.x - va.select.x) %>% 
  ggplot(aes(y = error.y, x = error.x)) + # geom_dots()
  geom_point(alpha = 0.5)

task2_df %>% mutate(error.y = va.ans.y - va.select.y, error.x = va.ans.x - va.select.x) %>% 
  filter(error.y < 0) %>% 
  select(error.y, data.ans.y, data.select.y, error.x) %>% 
  filter(error.x != 0)
```

Math model: 

$$\text{error}_i \sim \text{Exponential}(\lambda)$$
$$\log(\lambda) \sim \mathcal{N}(0, 1)$$

```{r}
task2_df %>% mutate(phy.error.x = phy.select.x - phy.ans.x, 
                    phy.error.y = phy.select.y - phy.ans.y) %>% 
  ggplot(aes(x = phy.error.y)) + geom_dots()

task2_df %>% mutate(phy.error.x = phy.select.x - phy.ans.x, 
                    phy.error.y = phy.select.y - phy.ans.y, 
                    pixel.error.y = pixel.select.y - pixel.ans.y) %>% 
  select(pixel.error.y) %>% 
  # ggplot(aes(x = pixel.error.y)) + geom_swarm()
  filter(pixel.error.y == 0)
```

```{r}
f <- bf(error.y ~ 1, 
        family = exponential())

# mu has log-link, so we don't pose any bounds on it 
p <- prior(normal(0, 1), class = Intercept)
```

```{r}
#| eval: false 
#| echo: false 
task2_df %>% mutate(error.y = va.ans.y - va.select.y) %>% 
  get_prior(f, data = .)

task2_df %>% mutate(error.y = abs(va.ans.y - va.select.y)) %>% 
  make_stancode(f, data = ., prior = p)
```

Fit the model:

```{r}
#| output: false 
s.2.va.y <- task2_df %>% mutate(error.y = abs(va.ans.y - va.select.y)) %>% 
  brm(formula = f, 
      prior = prior(normal(0, 1), class = Intercept), 
      cores = 4, 
      file = "models/s.2.va.y"
      )
```

Check fit and posterior: 

```{r}
summary(s.2.va.y)
```

```{r}
plot(s.2.va.y)
```

```{r}
#| code-fold: true 
#| warning: false 
pp_check(s.2.va.y, ndraws = 100)
```

check the posterior: 

```{r}
s.2.va.y %>% spread_draws(b_Intercept) %>% 
  mutate(rate = exp(b_Intercept)) %>% 
  ggplot(aes(x = rate)) + stat_halfeye()
```

--- 

Go from error on Y to error on X. Let's start with a random row. 

```{r}
set.seed(51)
task2_df %>% sample_n(1) %>% 
  select(contains("param"))

task2_df %>% sample_n(1) %>% left_join(participants)
```

This is what the plot looks like: 

```{r}
#| code-fold: true 
x_vals <- seq(-5, 5, 0.01)
y_vals <- dsgt(x, mu = -1.3, sigma = 1.3, lambda = 0.3, p = 2.9, q = 46.8, mean.cent = FALSE)

# plot
data.frame(x = x_vals, y = y_vals) %>% 
  ggplot(aes(x = x_vals, y = y_vals)) + 
  geom_line() + 
  xlim(-5, 5) + 
  ylim(0, 1) + 
  geom_vline(xintercept = -1.3, linetype = "dashed", color = "gray") + 
  geom_hline(yintercept = 0.21, linetype = "dashed", color = "gray") 
```

Create a function that uses `approxfunc` and `uniroot` to find value of `x` given `y`: 
-- Matt's suggestion --- use the actual density function `dsgt` and not the `approx` 

- Suppose we have only access to discrete values of `x` and `y`

```{r}
#| code-fold: true 

# Find an x value corresponding to a target y using uniroot
find_x_for_y_uniroot <- function(y_target, x_values, y_values, x_interval) {
  # Create interpolation function
  interp_func <- approxfun(x_values, y_values)
  
  # Define the function whose root we want to find: f(x) - y_target = 0
  root_func <- function(x) interp_func(x) - y_target
  
  # Find the root (where function equals zero)
  result <- try(uniroot(root_func, interval = x_interval, extendInt = "yes", tol = 1e-10), silent = FALSE)
  
  if (inherits(result, "try-error")) {
    return(NULL)  # No root found in this interval
  } else {
    return(result$root)
  }
}

# Find all x values for a given y by searching in different intervals
find_all_x_for_y <- function(y_target, x_values, y_values, n_segments = 5) {
  x_values <- unlist(x_values)
  y_values <- unlist(y_values)
  x_min <- min(x_values)
  x_max <- max(x_values)
  segment_width <- (x_max - x_min) / n_segments

  results <- numeric(0)
  for (i in 1:n_segments) {
    segment_start <- x_min + (i-1) * segment_width
    segment_end <- x_min + i * segment_width
    
    root <- find_x_for_y_uniroot(y_target, x_values, y_values, 
                                 c(segment_start, segment_end))
    
    if (!is.null(root)) {
      results <- c(results, root)
    }
  }
  return(results)
}
```

```{r}
data.true_y <- dsgt(-1.3, mu = -1.3, sigma = 1.3, lambda = 0.3, p = 2.9, q = 46.8, mean.cent = FALSE)
va.y_pred <- 2.648185 - sample(as.vector(posterior_predict(s.2.va.y)), 100) # this is in visual angle space 
phy.y_pred <- size(va.y_pred, 449)
pixel.y_pred <- phy_to_pixel_y(phy.y_pred, 5.14)
data.y_pred <- pixel_to_data_y(pixel.y_pred)

y_vals[y_vals > min(data.y_pred)]
y_vals[y_vals > max(data.y_pred)]

sapply(data.y_pred, function(x) find_all_x_for_y(x, x_vals, y_vals)) %>% 
  unlist(.) -> d

d %>% as.data.frame(.) %>% 
  mutate(pixel.x = data_to_pixel_x(`.`), 
         phy.x = pixel_to_phy_x(pixel.x, 5.14), 
         va.x = vis_angle(phy.x, 449) - 4.91137) %>% 
  ggplot(aes(x = va.x)) + geom_dots()
```

---

Let's try to generalize this to the original dataset: 

```{r}
task2_df %>% add_predicted_draws(s.2.va.y) %>% 
  nest(.) %>% 
  # create x_vals and y_vals 
  mutate(x_vals = rep(tibble(seq(-5, 5, 0.01)), n())) %>% 
  mutate(y_vals = list(tibble(unlist(x_vals), mu = param.mu, sigma = param.sigma, lambda = param.lambda, p = param.p, q = param.q, mean.cent = FALSE))) # %>% 
  unnest(data) %>% 
  mutate(va.pred.y = va.ans.y + .prediction, 
         phy.pred.y = size(va.pred.y, dist_to_screen), 
         pixel.pred.y = phy_to_pixel_y(phy.pred.y, pixelToMM), 
         data.pred.y = pixel_to_data_y(pixel.pred.y)) -> temp 


temp %>% ungroup(.) %>% select(contains("data")) %>% 
  mutate(data.error = data.select.y - data.pred.y) %>% 
  ggplot(aes(x = data.error)) + geom_dots()
  
# TODO --- can't translate from `data.pred.y` to `data.pred.x` at the moment ....... 
```

Hmm why is this not working ...? 

```{r}
set.seed(51)
task2_df %>% add_predicted_draws(s.2.va.y) %>% 
  nest(.) %>% 
  # create x_vals and y_vals 
  mutate(x_vals = rep(list(seq(-5, 5, 0.01)), n())) %>% 
  mutate(y_vals = list(dsgt(unlist(x_vals), mu = param.mu, sigma = param.sigma, lambda = param.lambda, p = param.p, q = param.q, mean.cent = FALSE))) %>% 
  ungroup(.) %>% 
  slice(1) %>% 
  unnest(data) %>% 
  mutate(va.pred.y = va.ans.y + .prediction, 
         phy.pred.y = size(va.pred.y, dist_to_screen), 
         pixel.pred.y = phy_to_pixel_y(phy.pred.y, pixelToMM), 
         data.pred.y = pixel_to_data_y(pixel.pred.y)) -> temp 

temp %>% select(data.pred.y, x_vals, y_vals) %>% 
  slice(1) %>% unnest(c(x_vals, y_vals)) %>% 
  mutate(data.pred.x = list(find_all_x_for_y(data.pred.y, x_vals, y_vals)))

temp_y <- temp %>% slice(1) %>% pull(y_vals) %>% unlist(.)
temp_x <- seq(-5, 5, 0.01) 
find_all_x_for_y(0.2466129, temp_x, temp_y)

data.frame(x = temp_x, y = temp_y) %>% 
  ggplot(aes(x = x, y = y)) + geom_line() + xlim(-5, 5) + ylim(0, 1) + 
  geom_hline(yintercept = 0.246) + 
  geom_vline(xintercept = c(0.5230175,2.0922857))

find_all_x_for_y(0.246, temp_x, temp_y, n_segments = 10)

# STUCK HERE BECAUSE WE CAN"T FIND IT UGH >>> 
```



Compare this to the actual error on x: 

```{r}
task2_df %>% mutate(error.va.x = va.select.x - va.ans.x) %>% 
  ggplot(aes(x = error.va.x)) + geom_dots()
```





## Task 2 - Vis Angle - error on X 

Math model: 

$$\begin{align}
\text{error_va}_{i} &\sim \text{Some Distribution}(\mu, \sigma) \\
\mu &\sim \mathcal{N}(\alpha, \sigma_\mu^2) \\ 
\sigma &\sim \text{Half-Cauchy}(\beta, \sigma_b^2)
\end{align}$$

We have at least two choices for the "Some Distribution" --- Normal and Laplace. 

### Task 2 - Vis Angle - Laplace distribution 

To fit a laplace distribution, we need to define our own custom distribution, since `brms` does not provide a default defined Laplace distributino. 

:::{.callout-note collapsed="true"}
There is a [wiki](https://en.wikipedia.org/wiki/Laplace_distribution) about Laplace distribution, which defines the pdf of a Laplace distribution to be $f(x | \mu, b) = \frac{1}{2b} \exp(-\frac{|x - \mu|}{b})$, where $\mu$ is a location parameter, and $b > 0$ is a scale parameter. And this is what the [stan manual](https://en.wikipedia.org/wiki/Laplace_distribution) defines the pdf of the **double exponential** distribution  --- $f(y|\mu, \sigma) = \frac{1}{2\sigma} \exp(- \frac{|y - \mu|}{\sigma})$, basically everything is the same except they're using different notations for the scale parameter ...  
:::

```{r}
# log of the laplace pdf 
laplace_lpdf <- "
real laplace_lpdf(real y, real mu, real sigma) {
  return -log(2 * sigma) - abs(y - mu) / sigma;
}
"

# define custom family 
c_family = custom_family(
  "laplace", 
  dpars = c("mu", "sigma"), 
  links = c("identity", "log"), 
  lb = c(NA, 0), 
  type = "real"
)
```

```{r}
# single participant 
f <- bf(error_va ~ 1, 
        family = c_family)

# define prior 
p1 <- c(
  prior(normal(0, 0.5), class = "Intercept"), 
  prior(cauchy(0, 0.5), class = "sigma", lb = 0)
)

p2 <- c(
  prior(lognormal(0, 0.25), class = "Intercept", lb=0), 
  prior(cauchy(0, 0.5), class = "sigma", lb = 0)
)
```

```{r}
#| eval: false 
#| echo: false 

# get prior
task2_df %>% mutate(error_va = va.select.x - va.ans.x) %>%
get_prior(formula = f,
          data = .)

# get stan code 
task2_df %>% mutate(error_va = va.select.x - va.ans.x) %>%
  make_stancode(formula = f, 
                data = .,
                prior = p2, 
                # stanvars = stanvar(scode = laplace_lpdf, block = "functions")
                )
```

Fit the model:

```{r}
#| output: false 

s.2.va.1 <- task2_df %>% mutate(error_va = va.select.x - va.ans.x) %>%
  brm(
    formula = f, 
    family = c_family, 
    stanvars = stanvar(scode = laplace_lpdf, block = "functions"), 
    prior = p1, 
    data = ., 
    chains = 4, 
    file = "models/s.2.va.1"
  )
```

Check the fitted model:

```{r}
summary(s.2.va.1)
plot(s.2.va.1)
```

Given that we are using custom families, we also need to define our custom function to perform posterior predictive checks: 

Define custom functions for posterior predictive check: 

```{r}
#| code-fold: true 
expose_functions(s.2.va.1, vectorize = TRUE)

# Define a random number generator for Laplace distribution
laplace_rng <- function(mu, sigma) {
  # Generate from Laplace distribution using uniform transformation
  u <- runif(length(mu)) - 0.5
  mu + sigma * sign(u) * (-log(1 - 2 * abs(u)))
}

# Define the posterior predict function for our custom family
posterior_predict_laplace <- function(i, prep, ...) {
  mu <- brms::get_dpar(prep, "mu", i = i)
  sigma <- brms::get_dpar(prep, "sigma", i = i)
  laplace_rng(mu, sigma)
}
```

```{r}
pp_check(s.2.va.1, ndraws = 100)
```

### Task 2 - Vis Angle - Normal distribution 

Same math model, except we now have $\texttt{error_va}_i \sim \mathcal{N}(\mu, \sigma^2)$, instead of a Laplace distribution. 

Formula: 

```{r}
f <- bf(error_va ~ 1,
        family = gaussian())

# define prior 
p <- c(
  prior(normal(0, 0.5), class = "Intercept"), 
  prior(cauchy(0, 0.5), class = "sigma")
)
```

```{r}
#| echo: false 
#| eval: false 

# get prior
task2_df %>% mutate(error_va = va.select.x - va.ans.x) %>%
get_prior(formula = f,
          data = .)

task2_df %>% mutate(error_va = va.select.x - va.ans.x) %>%
make_stancode(formula = f,
              data = ., 
              prior = p)
```

Fit the model: 

```{r}
#| output: false
#| label: task2-fit-model-3

s.2.va.2 <- task2_df %>% mutate(error_va = va.select.x - va.ans.x) %>%
  brm(
    formula = f,
    data = .,
    prior = p,
    chains = 4,
    file="models/s.2.va.2",
    save_pars = save_pars(all=TRUE)
  )
```

Check fitted results and posterior 

```{r}
summary(s.2.va.2)
plot(s.2.va.2)
pp_check(s.2.va.2, ndraws = 100)
```

Compared to the fit of the Laplace this one doesn't look as good ... 

### Task 2 - Vis Angle - Cauchy 

Note that a cauchy distribution is a student t distribution with degrees of freedom, `nu`, fixed to be 1. 

```{r}
f <- bf(error_va ~ 1,
        family = student())

p <- c(
  # constant prior for nu to make it cauchy 
  prior(constant(1), class = "nu"),
  prior(normal(0, 0.5), class = "Intercept"), 
  prior(cauchy(0, 0.5), class = "sigma")
)
```

```{r}
#| echo: false
#| eval: false

# get prior
task2_df %>% mutate(error_va = va.select.x - va.ans.x) %>%
get_prior(formula = f,
          data = .)

# check stan code 
task2_df %>% mutate(error_va = va.select.x - va.ans.x) %>%
make_stancode(formula = f,
              data = ., 
              prior = p)
```

Fit the model: 

```{r}
#| output: false 

s.2.va.3 <- task2_df %>% mutate(error_va = va.select.x - va.ans.x) %>%
  brm(
    formula = f, 
    prior = p, 
    data = ., 
    chains = 4, 
    file = "models/s.2.va.3"
  )
```

Check the fitted results: 

```{r}
summary(s.2.va.3)
plot(s.2.va.3)
pp_check(s.2.va.3, ndraws = 100)
```

### LOO comparisons 

Recall that the when using a custom `brms` family, we need to define our own funtions. First define the `log_lik` (log likelihood) related functions: 

```{r}
expose_functions(s.2.va.1, vectorize = TRUE)

# Define log-likelihood function for Laplace distribution
laplace_lpdf <- function(y, mu, sigma) {
  -log(2 * sigma) - abs(y - mu) / sigma
}

# Define log-likelihood function for brms
log_lik_laplace <- function(i, prep) {
  mu <- brms::get_dpar(prep, "mu", i = i)
  sigma <- brms::get_dpar(prep, "sigma", i = i)
  y <- prep$data$Y[i]
  laplace_lpdf(y, mu, sigma)
}

loo(s.2.va.1)
```

Loo comparison between all visual angle related models: 

```{r}
loo(s.2.va.1, s.2.va.2, s.2.va.3)
```

So the results are: **Laplace** > **Cauchy** > **Normal**. 

## Task 2 - Vis Angle - error on X - Varying variance 

Let's stick with the Laplace distribution for now. Let's check the posterior for the parameters: 

```{r}
s.2.va.1 %>% spread_draws(Intercept, sigma) %>% 
  pivot_longer(4:5) %>% 
  ggplot(aes(x = value, y = name)) + 
  stat_halfeye()
```

New math model: 
$$\begin{align*}
\text{error_va}_{i} &\sim \text{Laplace}(\mu, \sigma) \\
\mu &\sim \mathcal{N}(\bar{\mu}, \sigma_\mu^2) \\ 
\sigma_i &= f(\text{flat}_i) = \exp(\alpha + \beta \text{flat}_i)
\end{align*}$$

```{r}
#| column: margin 
s.2.va.1 %>% spread_draws(sigma) %>% 
  mutate(log_sigma = log(sigma)) %>% 
  ggplot(aes(x = log_sigma)) + stat_halfeye() + 
  labs(x = "log(sigma)")
```

Formula: 

```{r}
# single participant 
f <- bf(error_va ~ 1, 
        sigma ~ 1 + flat, 
        family = c_family)

# define prior 
p <- c(
  prior(normal(0, 0.5), class = "Intercept"), 
  prior(normal(0, 1), class = "Intercept", dpar = "sigma")
)

laplace_lpdf <- "
real laplace_lpdf(real y, real mu, real sigma) {
  return -log(2 * sigma) - abs(y - mu) / sigma;
}
"
```

```{r}
#| eval: false 
#| echo: false 

# get prior
task2_df %>% mutate(error_va = va.select.x - va.ans.x) %>%
get_prior(formula = f,
          data = .)

# get stan code 
task2_df %>% mutate(error_va = va.select.x - va.ans.x) %>%
  make_stancode(formula = f, 
                data = .,
                prior = p, 
                stanvars = stanvar(scode = laplace_lpdf, block = "functions")
                )
```

Fit the model: 

```{r}
s.2.va.4 <- task2_df %>% mutate(error_va = va.select.x - va.ans.x) %>%
  brm(formula = f, 
    family = c_family, 
    stanvars = stanvar(scode = laplace_lpdf, block = "functions"), 
    prior = p, 
    data = ., 
    chains = 4, 
    file = "models/s.2.va.4")
```

Check fit and posterior: 

```{r}
expose_functions(s.2.va.4, vectorize = TRUE)
summary(s.2.va.4)
plot(s.2.va.4)
pp_check(s.2.va.4, ndraws = 100)
```

Is this a better fit?

```{r}
expose_functions(s.2.va.4, vectorize = TRUE)

# Define log-likelihood function for Laplace distribution
laplace_lpdf <- function(y, mu, sigma) {
  -log(2 * sigma) - abs(y - mu) / sigma
}

loo(s.2.va.1, s.2.va.4)
```

Yes it is! 



## Task 2 - Physical Model 

TODO? Should this be the right approach or no? 

## Compare Vis Angle Models Against Physical Models 

TODO 