---
title: "mixture-model"
format: 
  html: 
    reference-location: margin
---

```{r}
#| echo: false
#| output: false
#| label: setup

library(tidyverse)
library(ggplot2)
# setting the theme 
theme_set(theme_minimal())
# model
library(brms)
# plot results 
library(tidybayes)
library(rstan)
library(sgt)
```

# Read in data and all processing 

- All the things selected by the participants will be named `xxx.select.xxx` 
- All the things related to the actual answer will be named `xxx.ans.xxx`

```{r}
#| label: read-in-data
#| code-fold: true
#| output: false 

df <- read.csv("vis-decode-slider_all_tidy.csv") %>% as_tibble(.)

# filter 
ids <- df %>% count(participantId) %>% filter(n == 492) %>% pull(participantId) 
df <- df %>% filter(participantId %in% ids)

# create a separate dataframe for just test related trials 
task_df <- df %>% filter(grepl("task", trialId) & grepl("test", trialId) ) %>% 
    select(participantId, trialId, responseId, answer) %>% 
    mutate(answer = as.numeric(answer)) %>% 
    pivot_wider(names_from = responseId, values_from = answer, names_repair = "universal") %>% 
  separate_wider_delim(trialId, delim = "_", names = c("task", "type", "id")) %>% 
  select(-type) %>% 
  rename(data.select.x = location.x, 
         data.select.y = location.y,
         pixel.select.x = pixel.x, 
         pixel.select.y = pixel.y)
```

```{r}
#| label: define-function
#| code-fold: true

# origin is top left  
data_to_pixel_y <- function(data_y) {
  return(-395 * data_y + 410)
}
data_to_pixel_x <- function(data_x) {
  return (53.5 * data_x + 317.5)
}

# origin is bottom left 
pixel_to_phy_x <- function(pixel, pxMM){
  (pixel - 50) / pxMM
}
pixel_to_phy_y <- function(pixel, pxMM){
  (410 - pixel) / pxMM
}

# return visual angle in degrees and not radian
vis_angle <- function(size, distance){
  return(2 * atan(size / (2 * distance)) * 180 / pi)
}

# tolerance for numerical precision 
tolerance <- 1e-10
```

```{r}
#| label: define-special-dfs
#| code-fold: true

p <- df %>% filter(participantId %in% ids) %>% 
  filter(grepl("pixelsPerMM", responseId) | grepl("prolificId", responseId)) %>% 
  select(participantId, responseId, answer) %>% 
  pivot_wider(names_from = responseId, values_from = answer) %>% 
  pull(participantId)

# custom dataframe 
pixel_to_mm <- data.frame(participantId = p, 
  pixelToMM = c(3.73, 3.27, 3.27, 5.03, 3.73, 3.25, 3.73, 3.27, 3.73, 3.27, 5.14, 3.30, 3.29)
)

vis_distance <- data.frame(participantId = p, 
                           dist_to_screen = c(426, 502, 500, 495, 485, 987, 635, 500, 479, 563, 449, 685, 462))

# combine 
participants <- pixel_to_mm %>% left_join(vis_distance, by = join_by(participantId))
```

# Task 1 --- split area into equal halves 

Load data: 

```{r}
#| label: get task 1 data 
#| code-fold: true 

task1_df <- task_df %>% filter(task == "task1") %>% 
  select(-slider.x, -slider.y) %>% 
  mutate(data.select.left_area = psgt(data.select.x, param.mu, param.sigma, param.lambda, param.p, param.q, mean.cent = FALSE), 
         data.ans.x = qsgt(0.5, param.mu, param.sigma, param.lambda, param.p, param.q, mean.cent = FALSE)) %>% 
  left_join(participants, by = join_by(participantId))
```

Ok here's the math model^[Note that the notation for a standard mixture model focuses on specifying the probability **density**, which is different than McElreath's approach of specifying things in a more generative fashion ...]: 

$$
\begin{align}
\Pr(y_i) & =  \lambda \cdot \Pr(\hat{y}^{\text{med}}_i) + (1 - \lambda) \cdot \Pr(\hat{y}^{\text{mod}}_i) \\
\hat{y}^{\text{med}}_i &\sim \mathcal{N}(y^\text{med}, (\sigma^\text{med}_{\text{PID}[i]})^2) \\ 
\hat{y}^{\text{mod}}_i &\sim \mathcal{N}(y^\text{mod}, (\sigma^{\text{mod}}_{\text{PID}[i]})^2) \\ 
(*) \,\, \lambda &\sim \text{Beta}(5, 5) 
\end{align}
$$

:::{.column-margin}
Perhaps a different way to write this in a generative fashion is: 
$$
\begin{align}
z_i &\sim \text{Categorical}(\pi_1, \pi_2) \\ 
y_i &\sim \mathcal{N}(\mu_{z_i}, \sigma_{z_i})
\end{align}
$$
where $z_i$ is the component indicator variable for observation $i$. 
:::



Let's try to write a simple brms model for this, note that right now $\lambda$ is just assumed to be drawn from Beta (or Dirichlet(1, 1)^[... which is going to be Uniform[0, 1] for the case of $K =2$])

```{r}
mix <- brms::mixture(gaussian, gaussian, order = "none")
formula <- bf(data.select.x ~ 0 + data.ans.x:mu1 + param.mu:mu2,
              mu1 ~ 0, 
              mu2 ~ 0, 
              sigma1 ~ 0 + (1 | participantId), 
              sigma2 ~ 0 + (1 | participantId)
              )
# get prior 
get_prior(formula = formula, data = task1_df, family = mix)

```

If we don't specify anything for `theta`, then theta is treated as drawn from a Dirichlet distribution, and theta values are assumed to be the same for all trials across all participants. 


```{r}
# # set prior 
# prior <- c(
#   prior(normal(0, 2), class = Intercept, dpar = mu1), 
#   prior(normal(0, 2), class = Intercept, dpar = mu2), 
#   # prior(beta(5, 5), class = theta), # dirichlet is the only valid prior for simplex parameters UGH 
#   prior(normal(0, 2), class = sigma1, lb = 0), # truncated normal dist
#   prior(normal(0, 2), class = sigma2, lb = 0) # truncate normal dist 
# )
```


Fit the model: 

```{r}
#| output: false 

mixture_model <- brm(
  formula = formula,
  data = task1_df, 
  family = mix, 
  # prior = prior, 
  chains = 4, 
  cores = 4, 
  iter = 10000, 
  warmup = 5000, 
  file = "models/task1", 
  control = list(adapt_delta = 0.95),
)
```

Check the fitted model: 

```{r}
summary(mixture_model)
pairs(mixture_model)
```

Let's look at the stan code of this: 

```{r}
make_stancode(formula = formula, 
              data = task1_df,
              family = mix)
```

Looking at the above sections^[termed `transformed parameters`, see [here](https://mc-stan.org/docs/reference-manual/blocks.html#program-block-transformed-parameters) for more details], we have the following: 

- `functions`: the place to define custom functions to be used in the model fitting process 
- `data`: declares all data that will be provided to th model from `R`. This includes observed variables, group identifiers, and any fixed values needed for the model. 
- `transformed data`: define deterministic transformations of data that only need to be computed once, before sampling begins. Useful for efficiency.
- `parameters`: the place to declare parameters that Stan will estimate. These are the unknowns in the model. 
- `model`: the core of the stan program, where we define the likelihood of the data given the parameters and specify the prior distributions. The `target` variable represents the **log posterior density** that Stan is trying to sample from. 

--- 

Let's say we try to add participant-level or row-level varying theta, then the stan code is going to look as follows: 

```{r}
stan_code <- "
functions {
}
data {
  int<lower=1> N; // total number of observations
  vector[N] Y; // observed values 
  vector[N] Y_med; // known median values 
  vector[N] Y_mod; // known mode values 
  
  // participant data 
  int<lower=1> N_p; // number of participants 
  array[N] int<lower=1> PID; // participant ID for each observation 
  
  // prior parameters 
  real<lower=0> alpha; // beta prior parameter for lambda 
  real<lower=0> beta; // beta prior parameter for lambda 
}
parameters {
  real<lower=0, upper=1> lambda; // mixing weight
  
  // participant-specific standard deviations 
  vector<lower=0>[N_p] sigma_med; 
  vector<lower=0>[N_p] sigma_mod; 
}
model {
  // priors
  lambda ~ beta(alpha, beta); 
  sigma_med ~ student_t(3, 0, 2.5); // TODO --- change this 
  sigma_mod ~ student_t(3, 0, 2.5); // TODO --- change this 
  
  // likelihood
  for (n in 1:N) {
    real mean_n = lambda * y_med[n] + (1 - lambda) * y_mod[n]; 
    real sd_n = sqrt(lambda^2 * square(sigma_med[PID[n]]) + (1 - lambda)^2 * square(sigma_mod[PID[n]]));
    
    y[n] ~ normal(mean_n, sd_n); 
  }
}
"


```