---
title: "Preliminary Model building"
format:
  html: 
    code-fold: false
    reference-location: margin
    df-print: paged
    toc: true
    code-overflow: wrap
---

```{r}
#| echo: false
#| output: false
#| label: setup

library(tidyverse)
library(ggplot2)
library(sgt)
library(numDeriv)
library(ggdist)
# setting the theme 
theme_set(theme_minimal())
# model
library(brms)
```

:::{.callout-caution}
Per Matt's advice: **Think in a generative way**
:::

# Read in data and all processing 

- All the things selected by the participants will be named `xxx.select.xxx` 
- All the things related to the actual answer will be named `xxx.ans.xxx`

```{r}
#| label: read-in-data
#| code-fold: true

df <- read.csv("vis-decode-slider_all_tidy.csv") %>% as_tibble(.)

# filter 
ids <- df %>% count(participantId) %>% filter(n == 492) %>% pull(participantId) 
df <- df %>% filter(participantId %in% ids)

# create a separate dataframe for just test related trials 
task_df <- df %>% filter(grepl("task", trialId) & grepl("test", trialId) ) %>% 
    select(participantId, trialId, responseId, answer) %>% 
    mutate(answer = as.numeric(answer)) %>% 
    pivot_wider(names_from = responseId, values_from = answer, names_repair = "universal") %>% 
  separate_wider_delim(trialId, delim = "_", names = c("task", "type", "id")) %>% 
  select(-type) %>% 
  rename(data.select.x = location.x, 
         data.select.y = location.y,
         pixel.select.x = pixel.x, 
         pixel.select.y = pixel.y)
```

```{r}
#| label: define-function
#| code-fold: true

# origin is top left  
data_to_pixel_y <- function(data_y) {
  return(-395 * data_y + 410)
}
data_to_pixel_x <- function(data_x) {
  return (53.5 * data_x + 317.5)
}

# origin is bottom left 
pixel_to_phy_x <- function(pixel, pxMM){
  (pixel - 50) / pxMM
}
pixel_to_phy_y <- function(pixel, pxMM){
  (410 - pixel) / pxMM
}

# return visual angle in degrees and not radian
vis_angle <- function(size, distance){
  return(2 * atan(size / (2 * distance)) * 180 / pi)
}
```

```{r}
#| label: define-special-dfs
#| code-fold: true

p <- df %>% filter(participantId %in% ids) %>% 
  filter(grepl("pixelsPerMM", responseId) | grepl("prolificId", responseId)) %>% 
  select(participantId, responseId, answer) %>% 
  pivot_wider(names_from = responseId, values_from = answer) %>% 
  pull(participantId)

# custom dataframe 
pixel_to_mm <- data.frame(participantId = p, 
  pixelToMM = c(3.73, 3.27, 3.27, 5.03, 3.73, 3.25, 3.73, 3.27, 3.73, 3.27)
)
vis_distance <- data.frame(participantId = p, 
                           dist_to_screen = c(426, 502, 500, 495, 485, 987, 635, 500, 479, 563))

# combine 
participants <- pixel_to_mm %>% left_join(vis_distance, by = join_by(participantId))
```

# Task 5 -- Project from dot to axes

```{r}
#| label: get task 5 data ready 
#| code-fold: true 

task5_df <- task_df %>% filter(task == "task5") %>% 
  select(participantId, task, id, data.select.x, data.select.y, slider.x, slider.y) %>% 
  rename(data.ans.x = data.select.x, 
         data.ans.y = data.select.y, 
         data.select.x = slider.x, 
         data.select.y = slider.y) %>% 
  left_join(participants, by = join_by(participantId)) %>% 
  # do all the calculations for user's selected 
  mutate(pixel.select.x = data_to_pixel_x(data.select.x), 
         pixel.select.y = data_to_pixel_y(data.select.y), 
         phy.select.x = pixel_to_phy_x(pixel.select.x, pixelToMM),
         phy.select.y = pixel_to_phy_y(pixel.select.y, pixelToMM), 
         va.select.x = vis_angle(phy.select.x, dist_to_screen),
         va.select.y = vis_angle(phy.select.y, dist_to_screen)) %>% 
  # do all the calculations for the actual answer
  mutate(pixel.ans.x = data_to_pixel_x(data.ans.x),
         pixel.ans.y = data_to_pixel_y(data.ans.y),
         phy.ans.x = pixel_to_phy_x(pixel.ans.x, pixelToMM),
         phy.ans.y = pixel_to_phy_y(pixel.ans.y, pixelToMM), 
         va.ans.x = vis_angle(phy.ans.x, dist_to_screen),
         va.ans.y = vis_angle(phy.ans.y, dist_to_screen))
```


```{r}
#| output: false 
#| code-fold: true
#| label: task 5 verify 

task5_df %>% ggplot(aes(x = pixel.select.x - pixel.ans.x)) + 
  geom_dots()

task5_df %>% ggplot(aes(x = pixel.select.y - pixel.ans.y)) + 
  geom_dots()

task5_df %>% ggplot(aes(x = phy.select.x - phy.ans.x)) + 
  geom_dots()  

task5_df %>% ggplot(aes(x = phy.select.y - phy.ans.y)) + 
  geom_dots() 

task5_df %>% ggplot(aes(x = va.select.x - va.ans.x)) + 
  geom_dots()  

task5_df %>% ggplot(aes(x = va.select.y - va.ans.y)) + 
  geom_dots()  

```


## Project from dot to X axes

Distribution of signed error: 

```{r}
#| code-fold: true

task5_df %>% ggplot(aes(x = va.select.x - va.ans.x)) + 
  geom_dots() +
  geom_vline(xintercept = 0, linetype="dashed", color="black") + 
  labs(title="Task 5 - Project from Dot to X-Axes - Vis Angle")
```

Relationship between signed error (in visual angle space) and distance to X-axes: 

```{r}
#| code-fold: true

task5_df %>% ggplot(aes(y = va.ans.y, x = va.select.x - va.ans.x)) + 
  geom_point(alpha = 0.5) +
  geom_vline(xintercept = 0, linetype="dashed", color="gray") + 
  labs(title="Task 5 - Project from Dot to X-Axes - Vis Angle")
```

What would be a potential model for this? We can have two models, where one models `dist_to_screen` in the variance part (and error is measured in the physical distance part) and the other measures visual angle. 

Model 1: 

$$
\begin{aligned}
\text{error}_{\text{va}}[i] &\sim \mathcal{N}(0, \sigma[i]) \\ 
\sigma[i] &= a \times \texttt{va.ans.y} \\
\implies \log(\sigma[i]) &= \log(a) + \log(\texttt{va.ans.y})
\end{aligned}
$$

Model 2: 

$$
\begin{aligned}
\text{error}_{\text{phy}}[i] &\sim \mathcal{N}(0, \sigma[i]) \\ 
\sigma[i] &= \text{dist}[i] \times \hat{\sigma}[i] \\ 
\hat{\sigma}[i] &\sim \text{Half-Cauchy}(0, 5)
\end{aligned}
$$

---

Let's fit these models with `brms`: 

Note that we're changing the prior from `cauchy(0, 5)` to `cauchy(0, 2)` for a tigheter fit ... 

```{r}
#| label: task5-fit-model-x 
#| output: false

m5.1.x <- task5_df %>% mutate(error_va = va.select.x - va.ans.x) %>%
  brm(
    formula = bf(error_va ~ 0, 
                 sigma ~ 0 + offset(log(va.ans.y)) + (1 | participantId)),
    data = .,
    family = gaussian(),
    prior = c(prior(cauchy(0, 2), class="sd", group="participantId", dpar="sigma")),
    control = list(adapt_delta = 0.95),
    chains = 4, 
    iter = 6000, # more iterations 
    file="models/m5.1.x"
)
```

What does the fit look like? 

```{r}
summary(m5.1.x)
plot(m5.1.x)
```

Posterior predictive check: 

```{r}
pp_check(m5.1.x, ndraws = 100)
```

```{r}
library(tidybayes)
library(bayesplot)

get_variables(m5.1.x)

m5.1.x %>% mcmc_areas(pars = vars(starts_with("r_")))
m5.1.x %>% mcmc_areas(pars = vars(starts_with("sd_")))

```

---

Recall the second model: 

$$
\begin{aligned}
\text{error}_{\text{phy}}[i] &\sim \mathcal{N}(0, \sigma[i]) \\ 
\sigma[i] &= \text{dist}[i] \times \hat{\sigma}[i] \\ 
\hat{\sigma}[i] &\sim \text{Half-Cauchy}(0, 5)
\end{aligned}
$$

Let's run the brms code for it: 

```{r}
task5_df %>% mutate(error_phy = phy.select.x - phy.ans.x) %>%
  rename(error = error_phy, dist = dist_to_screen) %>% 
  get_prior(bf(error ~ 0,
               sigma ~ 0 + offset(log(va.ans.y)) + offset(log(dist)) + (1 | participantId)), 
            data = .)
```


```{r}
m5.2.x <- task5_df %>% mutate(error_phy = phy.select.x - phy.ans.x) %>%
  rename(error = error_phy, dist = dist_to_screen) %>%
  brm(
    formula = bf(error ~ 0,
                 sigma ~ 0 + offset(log(phy.ans.y)) + offset(log(dist)) + (1 | participantId)),
    data = .,
    family = gaussian(),
    prior = c(prior(cauchy(0, 2), class="sd", group="participantId", dpar="sigma")),
    control = list(adapt_delta = 0.95),
    chains = 4,
    iter = 6000, # more iterations
    warmup=1000,
    file="models/m5.2.x"
)
```

```{r}
summary(m5.2.x)
plot(m5.2.x)
pp_check(m5.2.x, ndraws = 100)
```

Let's compare the two: 

```{r}
loo_compare(m5.1.x, m5.2.x, criterion="waic")
```


## Project from dot to Y Axes

Distribution of signed error: 

```{r}
#| code-fold: true 

task5_df %>% ggplot(aes(x = va.select.y - va.ans.y)) + 
  geom_dots() + 
  geom_vline(xintercept = 0, color="black", linetype="dashed") + 
  labs(title = "Task 5 - Project from dot to Y-Axes - Visual Angle")
```

Relationship between signed error and distance to x-axes (in visual angle space): 

```{r}
#| code-fold: true

task5_df %>% ggplot(aes(x = va.ans.x, y = va.select.y - va.ans.y)) + 
  geom_point(alpha = 0.5) + 
  geom_hline(yintercept = 0, linetype="dashed", color="gray") + 
  labs(title = "Task 5 - Project from dot to Y-Axes - Visual Angle")
```

We adopt a similar model and write the following formula: 

```{r}
#| label: task5-fit-model-y 
#| output: false 

m5.1.y <- task5_df %>% mutate(error_va = va.select.y - va.ans.y) %>%
  brm(
    formula = bf(error_va ~ 0, 
                 sigma ~ 0 + (1 | participantId)),
    data = .,
    family = gaussian(),
    prior = c(prior(cauchy(0, 2), class="sd", group="participantId", dpar="sigma")),
    control = list(adapt_delta = 0.95),
    chains = 4, 
    iter = 6000, # more iterations 
    file="models/m5.1.y"
)
```

```{r}
summary(m5.1.y)
plot(m5.1.y)
```

Posterior predictive check: 

```{r}
pp_check(m5.1.y, ndraws = 100)
```

### Second model 

```{r}
# TODO 
```


# Task 3 -- Find point on curve where `y == 0.5`

First we get the data:

```{r}
task3_df <- task_df %>% filter(task == "task3") %>% 
  select(-slider.x, -slider.y) %>% 
  left_join(participants, by = join_by(participantId)) %>% 
  # do all the calculations for user's selected 
  mutate(pixel.select.x = data_to_pixel_x(data.select.x), 
         pixel.select.y = data_to_pixel_y(data.select.y), 
         phy.select.x = pixel_to_phy_x(pixel.select.x, pixelToMM),
         phy.select.y = pixel_to_phy_y(pixel.select.y, pixelToMM), 
         va.select.x = vis_angle(phy.select.x, dist_to_screen),
         va.select.y = vis_angle(phy.select.y, dist_to_screen)) %>% 
  mutate(data.ans.y = 0.5, 
         data.ans.x = qsgt(0.5, param.mu, param.sigma, param.lambda, param.p, param.q, mean.cent = FALSE)) %>% 
  # do all the calculations for the actual answer
  mutate(pixel.ans.x = data_to_pixel_x(data.ans.x),
         pixel.ans.y = data_to_pixel_y(data.ans.y),
         phy.ans.x = pixel_to_phy_x(pixel.ans.x, pixelToMM),
         phy.ans.y = pixel_to_phy_y(pixel.ans.y, pixelToMM), 
         va.ans.x = vis_angle(phy.ans.x, dist_to_screen),
         va.ans.y = vis_angle(phy.ans.y, dist_to_screen))
```

```{r}
#| output: false 
#| code-fold: true
#| label: task 3 verify 

# verify that the results are of correct scale
task3_df %>% ggplot(aes(x = data.select.x - data.ans.x)) + 
  geom_dots()

task3_df %>% ggplot(aes(x = data.select.y - data.ans.y)) + 
  geom_dots()

task3_df %>% ggplot(aes(x = pixel.select.x - pixel.ans.x)) + 
  geom_dots()

task3_df %>% ggplot(aes(x = pixel.select.y - pixel.ans.y)) + 
  geom_dots()

task3_df %>% ggplot(aes(x = phy.select.x - phy.ans.x)) + 
  geom_dots()  

task3_df %>% ggplot(aes(x = phy.select.y - phy.ans.y)) + 
  geom_dots() 

task3_df %>% ggplot(aes(x = va.select.x - va.ans.x)) + 
  geom_dots()  

task3_df %>% ggplot(aes(x = va.select.y - va.ans.y)) + 
  geom_dots()  
```

Distribution of signed error: 

```{r}
#| code-fold: true

task3_df %>% ggplot(aes(x = va.select.y - va.ans.y)) + 
  geom_dots() + 
  geom_vline(xintercept = 0, linetype="dashed", color="black") + 
  labs(title="Task 3 -- CDF Median") 
```

Relationship between distance from the y-axes and the signed distribution: 

```{r}
task3_df %>% ggplot(aes(x = va.ans.x, y = va.select.y - va.ans.y)) + 
  geom_point(alpha = 0.5) + 
  geom_hline(yintercept = 0, linetype="dashed", color="black") + 
  labs(title="Task 3 -- CDF Median") 
```

The model we fit is going to be very similar to the ones we fitted for task 5. 

```{r}
#| label: task3-fit-model
#| output: false 

m3.1 <- task3_df %>% 
  mutate(error_va = va.select.y - va.ans.y) %>% 
  brm( 
    formula = bf(error_va ~ 0, 
                 sigma ~ 0 + (1 | participantId)), 
    data = ., 
    family = gaussian(),
    prior = c(prior(cauchy(0, 5), class="sd", group="participantId", dpar="sigma")),
    control = list(adapt_delta = 0.95),
    chains = 4, 
    iter = 6000, # more iterations
    file="models/m3.1"
)
```

```{r}
summary(m3.1)
plot(m3.1)
```

Posterior predictive check: 

```{r}
pp_check(m3.1, ndraws = 100)
```

```{r}
mcmc_areas(m3.1, pars=vars(!starts_with("l")))
```



---

Model 2

```{r}
# TODO 
```



<!-- What if we were to combine the dataframes and run a model together? Would this reduce the variance? Suppose we combine the project from dot to axes  -->
<!-- ```{r} -->
<!-- # TODO  -->
<!-- ``` -->

# Task 1 -- Split area into equal halves

```{r}
#| label: get task 1 data 

task1_df <- task_df %>% filter(task == "task1") %>% 
  select(-slider.x, -slider.y) %>% 
  mutate(data.select.left_area = psgt(data.select.x, param.mu, param.sigma, param.lambda, param.p, param.q, mean.cent = FALSE)) %>% 
  left_join(participants, by = join_by(participantId))
```

Plotting left area again lambda: 

```{r}
task1_df %>% ggplot(aes(x = param.lambda, y = data.select.left_area)) + 
  geom_point(alpha = 0.5) + 
  ylim(0, 1)

task1_df %>% ggplot(aes(x = param.lambda, y = data.select.x - param.mu)) + 
  geom_point(alpha = 0.5)

task1_df %>% ggplot(aes(x =  data.select.x - param.mu)) + 
  geom_dots()

task1_df %>% ggplot(aes(y =  data.select.x - param.mu, x = dist_to_screen)) + 
  geom_point()

task1_df %>% ggplot(aes(y =  data.select.left_area - 0.5, x = dist_to_screen)) + 
  geom_point()
```

Doesn't seem to be any trend connected to `dist_to_screen` ... 


# Task 2 -- Find highest point on curve 

First we get the data: 

```{r}
#| label: get task 2 data
#| code-fold: true 

task2_df <- task_df %>% filter(task == "task2") %>% 
  select(-slider.x, -slider.y) %>% 
  mutate(data.ans.x = param.mu, 
         data.ans.y = dsgt(param.mu, param.mu, param.sigma, param.lambda, param.p, param.q, mean.cent = FALSE),
         data.select.grad = numDeriv::grad(dsgt, data.select.x, mu = param.mu, sigma = param.sigma, lambda = param.lambda, p = param.p, q = param.q, mean.cent = FALSE), 
         data.select.angle = atan(data.select.grad) * 180 / pi) %>% 
  left_join(participants, by = join_by(participantId)) %>% 
  # calculate things related to participants' selection 
  mutate(phy.select.x = pixel_to_phy_x(pixel.select.x, pixelToMM), 
         phy.select.y = pixel_to_phy_y(pixel.select.y, pixelToMM),
         va.select.x = vis_angle(phy.select.x, dist_to_screen), 
         va.select.y = vis_angle(phy.select.y, dist_to_screen)) %>% 
  # calculate things related to answer 
  mutate(pixel.ans.x = data_to_pixel_x(data.ans.x), 
         pixel.ans.y = data_to_pixel_y(data.ans.y), 
         phy.ans.x = pixel_to_phy_x(pixel.ans.x, pixelToMM), 
         phy.ans.y = pixel_to_phy_y(pixel.ans.y, pixelToMM),
         va.ans.x = vis_angle(phy.ans.x, dist_to_screen),
         va.ans.y = vis_angle(phy.ans.y, dist_to_screen))
```

```{r}
#| layout-ncol: 2


task2_df %>% ggplot(aes(y = phy.ans.y - phy.select.y, x = dist_to_screen)) + 
  geom_point()

task2_df %>% ggplot(aes(y = va.ans.y - va.select.y, x = dist_to_screen)) + 
  geom_point()
```

A potential model: 

$$
\begin{aligned}
\text{error}_{\text{phy}}[i] \sim \text{Half-Normal}(\sigma[i]) \\ 
\sigma[i] \sim \text{Log-Normal}(0, 1)
\end{aligned}
$$

Turns that that brms does not have a default implementation of `half-normal` ... will need to figure out how to model this ... For now let's just try to fit this with what we've been previously doing ... 


```{r}
#| output: false
#| label: task2-fit-model

m2 <- task2_df %>% mutate(error_phy = phy.ans.y - phy.select.y) %>% 
  brm(formula = bf(
    error_phy ~ 0, 
    sigma ~ 0 + (1 | participantId)),
    data = ., 
      family = gaussian(),
      prior = c(
        prior(normal(0, 1), class="sd", group="participantId", dpar="sigma")
      ),
      control = list(adapt_delta = 0.95),
      chains = 4, 
      iter = 6000, # more iterations
      file="models/m2"
      )
```

Let's see some fitted results: 

```{r}
summary(m2)
plot(m2)
# posterior predictive check 
pp_check(m2, ndraws = 100)
```

Hmm so something is quite wrong with this specification ... 


---


Then we check to make sure that things are correct: 

```{r}
#| output: false 
#| code-fold: true 
#| label: task 2 verify 

task2_df %>% ggplot(aes(x = data.select.x - data.ans.x)) + 
  geom_dots()

task2_df %>% ggplot(aes(x = data.select.y - data.ans.y)) + 
  geom_dots()

task2_df %>% ggplot(aes(x = pixel.select.x - pixel.ans.x)) + 
  geom_dots()

task2_df %>% ggplot(aes(x = pixel.select.y - pixel.ans.y)) + 
  geom_dots()

task2_df %>% ggplot(aes(x = phy.select.x - phy.ans.x)) + 
  geom_dots()  

task2_df %>% ggplot(aes(x = phy.select.y - phy.ans.y)) + 
  geom_dots() 

task2_df %>% ggplot(aes(x = va.select.x - va.ans.x)) + 
  geom_dots()  

task2_df %>% ggplot(aes(x = va.select.y - va.ans.y)) + 
  geom_dots()  
```

Note that `grad.x` is calcultaing the angle of the slope^[i.e. gradient] at selection `x`. It is NOT the perceived angle. 

Let's plot the relation between the angle selected and the parameters: 

```{r}
#| code-fold: true 
#| layout-ncol: 2

task2_df %>% ggplot(aes(y = data.select.grad, x = param.p)) +
  geom_point(alpha = 0.5)

task2_df %>% ggplot(aes(y = data.select.grad, x = param.q)) +
  geom_point(alpha = 0.5)

task2_df %>% ggplot(aes(y = data.select.grad, x = param.lambda)) +
  geom_point(alpha = 0.5)

task2_df %>% ggplot(aes(y = data.select.grad, x = param.mu)) +
  geom_point(alpha = 0.5)

task2_df %>% ggplot(aes(y = data.select.grad, x = param.sigma)) +
  geom_point(alpha = 0.5)

task2_df %>% ggplot(aes(y = data.select.grad, x = dist_to_screen)) +
  geom_point(alpha = 0.5)
```

The only thing that is worth noting is the relationship between `data.select.grad` and `dist_to_screen`. What about the corresponding angle? 

```{r}
task2_df %>% ggplot(aes(y = data.select.angle, x = dist_to_screen)) +
  geom_point(alpha = 0.5)
```

---

How to calculate the actual angle, based on the selection? First we can check out the distribution of calculated angle (relative to the highest point?)

```{r}
task2_df %>% 
  mutate(diff.x = phy.select.x - phy.ans.x, 
         diff.y = phy.select.y - phy.ans.y, 
         angle = atan(diff.y / diff.x) * 180 / pi) %>% 
  ggplot(aes(x = angle)) + 
  geom_dots()
```

We are seeing these extreme outliers because `diff.x` is very, very small, almost close to 0. The above calculations does not deal well with very, very small denominators. Doing things in the visual angle space gives the same outliers. Let's just round things up to 3: 

```{r}
task2_df %>% mutate(diff.x = phy.select.x - phy.ans.x, 
                    diff.y = phy.select.y - phy.ans.y) %>% 
  mutate(diff.x = round(diff.x, 3), diff.y = round(diff.y, 3)) %>% 
  mutate(angle = case_when(diff.x == 0 ~ 0, 
                           diff.x != 0 ~ atan(diff.y / diff.x) * 180 / pi )) %>% 
  ggplot(aes(x = angle)) + 
  geom_dots()

task2_df %>% mutate(diff.x = phy.select.x - phy.ans.x, 
                    diff.y = phy.select.y - phy.ans.y) %>% 
  mutate(diff.x = round(diff.x, 3), diff.y = round(diff.y, 3)) %>% 
  mutate(angle = case_when(diff.x == 0 ~ 0, 
                           diff.x != 0 ~ atan(diff.y / diff.x) * 180 / pi )) %>% 
  ggplot(aes(x = angle, y = data.select.angle)) + 
  geom_point(alpha = 0.5) + 
  geom_abline(intercept = 0, slope = 1, color = "black", linetype = "dashed")
```

This just means that if we were to use the highest point and the selected point as ways to calculate the actual angle, then it is **larger** than the actual slope at the selected point. 

Is this newly calculated `angle` going to be related to `dist_to_screen`? 

```{r}
task2_df %>% mutate(diff.x = phy.select.x - phy.ans.x, 
                    diff.y = phy.select.y - phy.ans.y) %>% 
  mutate(diff.x = round(diff.x, 3), diff.y = round(diff.y, 3)) %>% 
  mutate(angle = case_when(diff.x == 0 ~ 0, 
                           diff.x != 0 ~ atan(diff.y / diff.x) * 180 / pi )) %>% 
  ggplot(aes(x = dist_to_screen, y = angle)) + 
  geom_point(alpha = 0.5)
```

Compare to the graph before, the difference is that this one has a bigger variance. 

What if we use the numbers in the visual angle space and not the physical space? 

```{r}
task2_df %>% mutate(diff.x = va.select.x - va.ans.x, 
                    diff.y = va.select.y - va.ans.y) %>% 
  mutate(diff.x = round(diff.x, 3), diff.y = round(diff.y, 3)) %>% 
  mutate(angle = case_when(diff.x == 0 ~ 0, 
                           diff.x != 0 ~ atan(diff.y / diff.x) * 180 / pi )) %>% 
  ggplot(aes(x = dist_to_screen, y = angle)) + 
  geom_point(alpha = 0.5)
```

Hmm doesn't seem to be much different, which is to be expected, as slope is unit-less. 

--- 

# Task 4 -- Find slope 

```{r}
#| label: get task 4 data 

task4_df <- task_df %>% filter(task == "task4") %>% 
  select(-slider.x, -slider.y) %>% 
  mutate(data.select.slope = dsgt(data.select.x, param.mu, param.sigma, param.lambda, param.p, param.q, mean.cent=FALSE), 
         data.ans.slope = dsgt(param.mu, param.mu, param.sigma, param.lambda, param.p, param.q, mean.cent=FALSE)) %>% 
  left_join(participants, by = join_by(participantId))
```

Let's first see the distribution of signed error: 

```{r}
task4_df %>% ggplot(aes(x = data.select.slope - data.ans.slope)) + 
  geom_dots()
```

It seems that the selected slope is consistently smaller than the actual slope of the answer. 

Let's see if there's any obvious relation between signed error and parameters of the distribution: 

```{r}
#| layout-ncol: 2
#| code-fold: true 


task4_df %>% ggplot(aes(y = data.select.slope - data.ans.slope, x = dist_to_screen)) + 
  geom_point()

task4_df %>% ggplot(aes(y = data.select.slope - data.ans.slope, x = param.mu)) + 
  geom_point()

task4_df %>% ggplot(aes(y = data.select.slope - data.ans.slope, x = param.sigma)) + 
  geom_point()

task4_df %>% ggplot(aes(y = data.select.slope - data.ans.slope, x = param.lambda)) + 
  geom_point()

task4_df %>% ggplot(aes(y = data.select.slope - data.ans.slope, x = param.p)) + 
  geom_point()

task4_df %>% ggplot(aes(y = data.select.slope - data.ans.slope, x = param.q)) + 
  geom_point()
```

I don't see any apparent trends ... 