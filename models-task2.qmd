---
title: "Models Task 2"
format:
  html: 
    code-fold: false
    reference-location: margin
    df-print: paged
    toc: true
    code-overflow: wrap
---

```{r}
#| echo: false
#| output: false
#| label: setup

library(tidyverse)
library(ggplot2)
library(sgt)
library(numDeriv)
library(ggdist)
# setting the theme 
theme_set(theme_minimal())
# model
library(brms)
# plot results 
library(tidybayes)
```

# Set up 

read in data and write functions for processing: 

```{r}
#| label: read-in-data
#| code-fold: true

df <- read.csv("vis-decode-slider_all_tidy.csv") %>% as_tibble(.)

# filter 
ids <- df %>% count(participantId) %>% filter(n == 492) %>% pull(participantId) 
df <- df %>% filter(participantId %in% ids)

# create a separate dataframe for just test related trials 
task_df <- df %>% filter(grepl("task", trialId) & grepl("test", trialId) ) %>% 
    select(participantId, trialId, responseId, answer) %>% 
    mutate(answer = as.numeric(answer)) %>% 
    pivot_wider(names_from = responseId, values_from = answer, names_repair = "universal") %>% 
  separate_wider_delim(trialId, delim = "_", names = c("task", "type", "id")) %>% 
  select(-type) %>% 
  rename(data.select.x = location.x, 
         data.select.y = location.y,
         pixel.select.x = pixel.x, 
         pixel.select.y = pixel.y)
```

```{r}
#| label: define-function
#| code-fold: true

# origin is top left  
data_to_pixel_y <- function(data_y) {
  return(-395 * data_y + 410)
}
data_to_pixel_x <- function(data_x) {
  return (53.5 * data_x + 317.5)
}

# origin is bottom left 
pixel_to_phy_x <- function(pixel, pxMM){
  (pixel - 50) / pxMM
}
pixel_to_phy_y <- function(pixel, pxMM){
  (410 - pixel) / pxMM
}

# return visual angle in degrees and not radian
vis_angle <- function(size, distance){
  return(2 * atan(size / (2 * distance)) * 180 / pi)
}

# tolerance for numerical precision 
tolerance <- 1e-10
```

```{r}
#| label: define-special-dfs
#| code-fold: true

p <- df %>% filter(participantId %in% ids) %>% 
  filter(grepl("pixelsPerMM", responseId) | grepl("prolificId", responseId)) %>% 
  select(participantId, responseId, answer) %>% 
  pivot_wider(names_from = responseId, values_from = answer) %>% 
  pull(participantId)

# custom dataframe 
pixel_to_mm <- data.frame(participantId = p, 
  pixelToMM = c(3.73, 3.27, 3.27, 5.03, 3.73, 3.25, 3.73, 3.27, 3.73, 3.27, 5.14, 3.30, 3.29)
)

vis_distance <- data.frame(participantId = p, 
                           dist_to_screen = c(426, 502, 500, 495, 485, 987, 635, 500, 479, 563, 449, 685, 462))

# combine 
participants <- pixel_to_mm %>% left_join(vis_distance, by = join_by(participantId))
```


# Task 2 -- Find highest point on curve 

First we get the data: 

```{r}
#| label: get task 2 data
#| code-fold: true 

task2_df <- task_df %>% filter(task == "task2") %>% 
  select(-slider.x, -slider.y) %>% 
  mutate(data.ans.x = param.mu, 
         data.ans.y = dsgt(param.mu, param.mu, param.sigma, param.lambda, param.p, param.q, mean.cent = FALSE),
         data.select.grad = numDeriv::grad(dsgt, data.select.x, mu = param.mu, sigma = param.sigma, lambda = param.lambda, p = param.p, q = param.q, mean.cent = FALSE), 
         data.select.angle = atan(data.select.grad) * 180 / pi) %>% 
  left_join(participants, by = join_by(participantId)) %>% 
  # calculate things related to participants' selection 
  mutate(phy.select.x = pixel_to_phy_x(pixel.select.x, pixelToMM), 
         phy.select.y = pixel_to_phy_y(pixel.select.y, pixelToMM),
         va.select.x = vis_angle(phy.select.x, dist_to_screen), 
         va.select.y = vis_angle(phy.select.y, dist_to_screen)) %>% 
  # calculate things related to answer 
  mutate(pixel.ans.x = data_to_pixel_x(data.ans.x), 
         pixel.ans.y = data_to_pixel_y(data.ans.y), 
         phy.ans.x = pixel_to_phy_x(pixel.ans.x, pixelToMM), 
         phy.ans.y = pixel_to_phy_y(pixel.ans.y, pixelToMM),
         va.ans.x = vis_angle(phy.ans.x, dist_to_screen),
         va.ans.y = vis_angle(phy.ans.y, dist_to_screen))
```

Some preliminary checks of relations: 

```{r}
#| layout-ncol: 2

task2_df %>% ggplot(aes(y = phy.ans.y - phy.select.y, x = dist_to_screen)) + 
  geom_point()

task2_df %>% ggplot(aes(y = va.ans.y - va.select.y, x = dist_to_screen)) + 
  geom_point()

task2_df %>% ggplot(aes(x = va.ans.y - va.select.y)) + geom_dots()
task2_df %>% ggplot(aes(x = phy.ans.y - phy.select.y)) + geom_dots()

# for the sake of determining the variance, let's only look at `data` space for now ... 

task2_df %>% mutate(error_va = va.ans.y - va.select.y) %>% 
  mutate(error_va = ifelse(abs(error_va) < 1e-8, 0, error_va)) %>%  
  # filter(error_va != 0) %>% 
  ggplot(aes(x = va.ans.x - va.select.x)) + 
  geom_dots()

task2_df %>% mutate(error_va = va.ans.y - va.select.y) %>% 
  mutate(error_va = ifelse(abs(error_va) < 1e-8, 0, error_va)) %>%  
  # filter(error_va != 0) %>% 
  ggplot(aes(x = data.ans.x - data.select.x)) + 
  geom_dots()
# this looks like a laplace distribution 
```

## Model 1 -- Vis Angle space

Based on our prior assumptions so far, the vis angle space model should not include dist_to_screen but the physical model should. Therefore, a potential model looks as follows: 

$$
\begin{align}
\text{error}_{\text{va}}[i] \sim \text{Half-Normal}(\sigma_{\text{PID}[i]}) \\ 
\sigma_j \sim \text{Log-Normal}(0, 1)
\end{align}
$$

Specify formula: 

```{r}
#| label: task 2 formula 1 

f <- bf(error_va | trunc(lb = 0) ~ 0, 
        sigma ~ 0 + (1 | participantId), 
        family = gaussian())

# get prior 
task2_df %>% mutate(error_va = va.select.x - va.ans.x) %>%
get_prior(formula = f, 
          data = .)

p <- prior(lognormal(0, 1), class = "sd", dpar="sigma", group="participantId")
```

Hmm the half-normal model doesn't look quite right, perhaps this follows closer to an exponential distribution? Also we need to take care of teh number of times thigns were zero, so this should be a **zero-inflated exponential model**. Something like the following: 

$$
\begin{align}
\text{error}_{\text{va}}[i] &\sim \text{Exponential}(\lambda_{\text{PID}[i]}) \\ 
\lambda &= \exp(\alpha + u_j) \\ 
\alpha &\sim \mathcal{N}(0, 1) \\ 
u_j &\sim \mathcal{N}(0, \sigma_u^2) \\ 
\sigma_u &\sim \text{Half-Cauchy}(0, 5) 
\end{align}
$$

The corresponding `brms` formula would be as follows: 

```{r}
#| label: task 2 formula 2

f2 <- bf(error_va ~ 1 + (1 | participantId), 
        family = exponential())

# get prior 
task2_df %>% mutate(error_va = va.select.x - va.ans.x) %>%
get_prior(formula = f2, 
          data = .)

p <- c(
  prior(normal(0, 1), class = Intercept), 
  prior(cauchy(0, 5), class = "sd", group = "participantId")
)
```

Let's fit the model: 

```{r}
#| output: false
#| label: task2-fit-model-3

m2.3 <- task2_df %>% mutate(error_va = va.ans.y - va.select.y) %>% 
  mutate(error_va = ifelse(abs(error_va) < 1e-8, 0, error_va)) %>% 
  mutate(error_va = ifelse(error_va < 0, 0, error_va)) %>% 
  brm(formula = f2,
      data = ., 
      prior = p,
      control = list(adapt_delta = 0.99), # note this is higher than 0.95
      chains = 4, 
      iter = 8000, # more iterations
      warmup = 2000, # higher than usual 
      file="models/m2.3", 
      save_pars = save_pars(all=TRUE)
      )
```



:::{.caution}
While doing the fitting I found some issues ... For task 2, `error_va = va.ans.y - va.select.y` should always be non-negative, but I got some negative values that are very, very small. I am setting a tolerance of `1e-12` --- any value smaller than this range will be regarded as 0. See the following for the negative values 

```{r}
task2_df %>% mutate(error_va = va.ans.y - va.select.y) %>% filter(error_va < 0) %>% 
  select(data.select.y, data.ans.y) %>% 
  mutate(diff = data.select.y - data.ans.y) %>% 
  pull(diff)
```

:::

Fit the model: 

```{r}
#| output: false
#| label: task2-fit-model

m2.1 <- task2_df %>% mutate(error_va = va.ans.y - va.select.y) %>% 
  mutate(error_va = ifelse(abs(error_va) < 1e-8, 0, error_va)) %>% 
  brm(formula = f,
      data = ., 
      prior = p,
      control = list(adapt_delta = 0.99), # note this is higher than 0.95
      chains = 4, 
      iter = 8000, # more iterations
      warmup = 2000, # higher than usual 
      file="models/m2.1", 
      save_pars = save_pars(all=TRUE)
      )
```

Let's see some fitted results: 

```{r}
summary(m2.1)
plot(m2.1)
# posterior predictive check 
pp_check(m2.1, ndraws = 100)
```

## Model 2 -- Physical

Math model: 

$$
\begin{aligned}
\text{error}_{\text{phy}}[i] &\sim \text{Half-Normal}(\sigma[i]) \\ 
\sigma[i] &= \texttt{dist_to_screen} \times \hat{\sigma}[i]\\ 
\hat{\sigma}[i] &\sim \text{Log-Normal}(0, 1)
\end{aligned}
$$

Formula: 

```{r}
f <- bf(error_phy | trunc(lb = 0) ~ 0, 
        sigma ~ 0 + offset(log(dist_to_screen)) + (1 | participantId), 
        family = gaussian())

p <- prior(lognormal(0, 1), class = "sd", dpar="sigma", group="participantId")
```

Fit model: 

```{r}
#| output: false 

m2.2 <- task2_df %>% 
  mutate(error_phy = phy.ans.y - phy.select.y) %>% 
  # note that the usual tolerance of 1e-12 is not good enough 
  # mutate(error_phy = ifelse(abs(error_phy) < 1e-8, 0, error_phy)) %>% 
  # let's just make everything negative to be 0 
  mutate(error_phy = ifelse(error_phy < 0, 0, error_phy)) %>% 
  brm(formula = f,
      data = ., 
      prior = p,
      control = list(adapt_delta = 0.99), # note this is higher than 0.95
      chains = 4, 
      iter = 8000, # more iterations
      warmup = 2000, # higher than usual 
      file="models/m2.2", 
      save_pars = save_pars(all=TRUE)
      )
```

Check fit: 

```{r}
summary(m2.2)
plot(m2.2)
pp_check(m2.2, ndraws = 100)
```

## Compare model 1 and model 2 

```{r}
m2.1 <- add_criterion(m2.1, "loo", moment_match=TRUE, recompile=TRUE)
m2.2 <- add_criterion(m2.2, "loo", moment_match = TRUE, recompile=TRUE)

loo_compare(m2.1, m2.2)
```

The visual angle version is also better. 

---

Then we check to make sure that things are correct: 

```{r}
#| output: false 
#| code-fold: true 
#| label: task 2 verify 

task2_df %>% ggplot(aes(x = data.select.x - data.ans.x)) + 
  geom_dots()

task2_df %>% ggplot(aes(x = data.select.y - data.ans.y)) + 
  geom_dots()

task2_df %>% ggplot(aes(x = pixel.select.x - pixel.ans.x)) + 
  geom_dots()

task2_df %>% ggplot(aes(x = pixel.select.y - pixel.ans.y)) + 
  geom_dots()

task2_df %>% ggplot(aes(x = phy.select.x - phy.ans.x)) + 
  geom_dots()  

task2_df %>% ggplot(aes(x = phy.select.y - phy.ans.y)) + 
  geom_dots() 

task2_df %>% ggplot(aes(x = va.select.x - va.ans.x)) + 
  geom_dots()  

task2_df %>% ggplot(aes(x = va.select.y - va.ans.y)) + 
  geom_dots()  
```

Note that `grad.x` is calcultaing the angle of the slope^[i.e. gradient] at selection `x`. It is NOT the perceived angle. 

Let's plot the relation between the angle selected and the parameters: 

```{r}
#| code-fold: true 
#| layout-ncol: 2

task2_df %>% ggplot(aes(y = data.select.grad, x = param.p)) +
  geom_point(alpha = 0.5)

task2_df %>% ggplot(aes(y = data.select.grad, x = param.q)) +
  geom_point(alpha = 0.5)

task2_df %>% ggplot(aes(y = data.select.grad, x = param.lambda)) +
  geom_point(alpha = 0.5)

task2_df %>% ggplot(aes(y = data.select.grad, x = param.mu)) +
  geom_point(alpha = 0.5)

task2_df %>% ggplot(aes(y = data.select.grad, x = param.sigma)) +
  geom_point(alpha = 0.5)

task2_df %>% ggplot(aes(y = data.select.grad, x = dist_to_screen)) +
  geom_point(alpha = 0.5)
```

The only thing that is worth noting is the relationship between `data.select.grad` and `dist_to_screen`. What about the corresponding angle? 

```{r}
task2_df %>% ggplot(aes(y = data.select.angle, x = dist_to_screen)) +
  geom_point(alpha = 0.5)
```

---

How to calculate the actual angle, based on the selection? First we can check out the distribution of calculated angle (relative to the highest point?)

```{r}
task2_df %>% 
  mutate(diff.x = phy.select.x - phy.ans.x, 
         diff.y = phy.select.y - phy.ans.y, 
         angle = atan(diff.y / diff.x) * 180 / pi) %>% 
  ggplot(aes(x = angle)) + 
  geom_dots()
```

We are seeing these extreme outliers because `diff.x` is very, very small, almost close to 0. The above calculations does not deal well with very, very small denominators. Doing things in the visual angle space gives the same outliers. Let's just round things up to 3: 

```{r}
task2_df %>% mutate(diff.x = phy.select.x - phy.ans.x, 
                    diff.y = phy.select.y - phy.ans.y) %>% 
  mutate(diff.x = round(diff.x, 3), diff.y = round(diff.y, 3)) %>% 
  mutate(angle = case_when(diff.x == 0 ~ 0, 
                           diff.x != 0 ~ atan(diff.y / diff.x) * 180 / pi )) %>% 
  ggplot(aes(x = angle)) + 
  geom_dots()

task2_df %>% mutate(diff.x = phy.select.x - phy.ans.x, 
                    diff.y = phy.select.y - phy.ans.y) %>% 
  mutate(diff.x = round(diff.x, 3), diff.y = round(diff.y, 3)) %>% 
  mutate(angle = case_when(diff.x == 0 ~ 0, 
                           diff.x != 0 ~ atan(diff.y / diff.x) * 180 / pi )) %>% 
  ggplot(aes(x = angle, y = data.select.angle)) + 
  geom_point(alpha = 0.5) + 
  geom_abline(intercept = 0, slope = 1, color = "black", linetype = "dashed")
```

This just means that if we were to use the highest point and the selected point as ways to calculate the actual angle, then it is **larger** than the actual slope at the selected point. 

Is this newly calculated `angle` going to be related to `dist_to_screen`? 

```{r}
task2_df %>% mutate(diff.x = phy.select.x - phy.ans.x, 
                    diff.y = phy.select.y - phy.ans.y) %>% 
  mutate(diff.x = round(diff.x, 3), diff.y = round(diff.y, 3)) %>% 
  mutate(angle = case_when(diff.x == 0 ~ 0, 
                           diff.x != 0 ~ atan(diff.y / diff.x) * 180 / pi )) %>% 
  ggplot(aes(x = dist_to_screen, y = angle)) + 
  geom_point(alpha = 0.5)
```

Compare to the graph before, the difference is that this one has a bigger variance. 

What if we use the numbers in the visual angle space and not the physical space? 

```{r}
task2_df %>% mutate(diff.x = va.select.x - va.ans.x, 
                    diff.y = va.select.y - va.ans.y) %>% 
  mutate(diff.x = round(diff.x, 3), diff.y = round(diff.y, 3)) %>% 
  mutate(angle = case_when(diff.x == 0 ~ 0, 
                           diff.x != 0 ~ atan(diff.y / diff.x) * 180 / pi )) %>% 
  ggplot(aes(x = dist_to_screen, y = angle)) + 
  geom_point(alpha = 0.5)
```

Hmm doesn't seem to be much different, which is to be expected, as slope is unit-less. 

--- 
