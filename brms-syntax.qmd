---
title: "brms-syntax"
format: html
---

```{r}
#| echo: false
#| output: false
#| label: setup

library(tidyverse)
library(ggplot2)
# setting the theme 
theme_set(theme_minimal())
# model
library(brms)
# plot results 
library(tidybayes)
```

# Get simulation data 

Model: 

$$\begin{align*}
y_i &\sim \mathcal{N}(\alpha_{\text{PID}[i]}, \beta_{\text{PID}[i]}) \\ 
\alpha_j &\sim \mathcal{N}(5, 1), j \in [50] \\ 
\beta_j &\sim |\mathcal{N}(0, 2)|, j \in [50]
\end{align*}$$

Let's say we have 100 participants. 

```{r}
n <- 50
trials <- 20
intercept <- rnorm(n, mean = 5, sd = 1)
variance <- abs(rnorm(n, mean = 0, sd = 1))

data <- data.frame(PID = rep(1:n, each = trials), 
           mean = rep(intercept, each = trials), 
           variance = rep(variance, each = trials)) %>% 
   mutate(out = map2_dbl(mean, variance, ~rnorm(1, mean = .x, sd = .y)))

# get a sense of what data looks like 
data %>%
  ggplot(aes(x = out)) +
  geom_dots()
```

# Model 1 

```{r}
f <- bf(out ~ 1)

get_prior(f, data = data)
```

```{r}
#| output: false 
#| eval: false 
m1 <- brm(f, data = data, family = gaussian)
```

We can check the variables from the fitted model using `get_variables`:

```{r}
#| eval: false 
get_variables(m1)
```

There are a lot of variables here, and we only care about those that are before `lprior`, namely: 1) `b_Intercept`, 2) `sigma`, and 3) `Intercept`. 

To get a better sense of what's happening under the hood, it makes sense to check the stan code, which we can do as follows: 

```{r}
#| column: margin 
make_stancode(bf(out ~ 1), data = data, family = gaussian())
```

---

The above stan code has several blocks. Let's examine the non-empty ones one by one: 

```default
data {
  int<lower=1> N;  // total number of observations      # <1>
  vector[N] Y;  // response variable                    # <2>
  int prior_only;  // should the likelihood be ignored? # <3> 
}
```
1. The number of rows in `data`
2. The response variable, which is the `out` column in `data`, which has length `N`
3. A flag that tells `brms` whether we're doing a prior predictive check 


```default
parameters {
  real Intercept;  // temporary intercept for centered predictors # <4>
  real<lower=0> sigma;  // dispersion parameters                  # <4> 
}
```
4. Notice that these are scalar values, *NOT* vector values. They correspond to `coef = Intercept` and `coef = sigma` in the `get_prior` results. 

```default
transformed parameters {
  real lprior = 0;  // prior contributions to the log posterior 
  lprior += student_t_lpdf(Intercept | 3, 5.2, 2.5); # <5> 
  lprior += student_t_lpdf(sigma | 3, 0, 2.5)        # <6> 
    - 1 * student_t_lccdf(0 | 3, 0, 2.5);            # <6> 
}
```
5. The default Intercept is drawn from `student_t(3, 5.2, 2.5)` 
6. The default `sigma`, with `lb = 0` 

```default 
model {
  // likelihood including constants
  if (!prior_only) {
    // initialize linear predictor term
    vector[N] mu = rep_vector(0.0, N);     # <7>
    mu += Intercept;                       # <7> 
    target += normal_lpdf(Y | mu, sigma);  # <8> 
  }
  // priors including constants
  target += lprior;                        # <9>
}
```
7. Create a vector of length `N`, where each element is `Intercept`. 
8. The likelihood function, corresponds to $y_i \sim \mathcal{N}(\mu, \sigma)$ 
9. Hmm I'm actually confused cause this is different than how I'm implementing things ...

```default
generated quantities {
  // actual population-level intercept
  real b_Intercept = Intercept; # <10>
}
```
10. This tells us that `b_Intercept` is just `Intercept` by construction. 


<!-- Check fitted results:  -->

<!-- ```{r} -->
<!-- summary(m1) -->
<!-- plot(m1) -->

<!-- m1 %>% spread_draws(b_Intercept, sigma, Intercept) %>% -->
<!--   pivot_longer(4:ncol(.)) %>%  -->
<!--   ggplot(aes(x = value, y = name)) +  -->
<!--   stat_halfeye() -->
<!-- ``` -->





<!-- From the above we know that by construction, `b_Intercept` = `Intercept`.  -->

<!-- # Model 1.1  -->

<!-- ```{r} -->
<!-- f <- bf(out ~ 0 + (1 | PID)) -->

<!-- get_prior(f, data = data) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- #| output: false  -->

<!-- m1.1 <- brm(f, data = data, family = gaussian) -->
<!-- get_variables(m1.1) -->
<!-- make_stancode(bf(out ~ 0 + (1 | PID)), data = data, family = gaussian()) -->
<!-- ``` -->

<!-- From the `get_variables` outcome, there are the things we care about:  -->
<!-- - `sd_PID__Intercept`: standard deviation  -->
<!-- - `sigma`: unclear ...  -->
<!-- - `r_PID[num, Intercept]`: intercept per participant  -->

<!-- Check output:  -->

<!-- ```{r} -->
<!-- summary(m1.1) -->
<!-- plot(m1.1) -->
<!-- ``` -->



# Model 2

```{r}
f <- bf(out ~ 1 + (1 | PID))

get_prior(f, data = data)
```

The middle three rows are the new ones compared to Model 1, when we're adding `(1|PID)`. 

```{r}
#| output: false
#| eval: false 

m2 <- brm(f, data = data, family = gaussian)
get_variables(m2)
```

`get_variables` give us:

- `b_Intercept`
- `sd_PID__Intercept` --- NEW
- `sigma`
- `Intercept`
- `r_PID[num, Intercept]` --- NEW 

Stan code:

```{r}
#| column: margin 
make_stancode(out ~ 1 + (1 | PID),
              data = data,
              family = gaussian)
```

Let's walk through this one, annotating only the new ones compared to what we had before: 

```default
data {
  int<lower=1> N;  // total number of observations
  vector[N] Y;  // response variable
  // data for group-level effects of ID 1
  int<lower=1> N_1;  // number of grouping levels                   # <1>
  int<lower=1> M_1;  // number of coefficients per level            # <2>
  array[N] int<lower=1> J_1;  // grouping indicator per observation # <3> 
  // group-level predictor values
  vector[N] Z_1_1;                                                  # <4>
  int prior_only;  // should the likelihood be ignored?             
}
```
1. The number of different levels in the group, `PID`. Which would be the number of participants. 
2. ??? 
3. This array is a mapping function, which tells us which participant this row is corresponding to. 
4. ???  

```default
parameters {
  real Intercept;  // temporary intercept for centered predictors
  real<lower=0> sigma;  // dispersion parameter
  vector<lower=0>[M_1] sd_1;  // group-level standard deviations   # <5>
  array[M_1] vector[N_1] z_1;  // standardized group-level effects # <6>
}
```
5. If `M_1 = 1`, what does this even mean? It becomes a one?  
6. ??? What is this?? How do you arran a vector ...? 

```default
transformed parameters {
  vector[N_1] r_1_1;  // actual group-level effects                # <7> 
  real lprior = 0;  // prior contributions to the log posterior
  r_1_1 = (sd_1[1] * (z_1[1]));                                    # <8> 
  lprior += student_t_lpdf(Intercept | 3, 5.3, 2.5);
  lprior += student_t_lpdf(sigma | 3, 0, 2.5)
    - 1 * student_t_lccdf(0 | 3, 0, 2.5);
  lprior += student_t_lpdf(sd_1 | 3, 0, 2.5)                       # <9> 
    - 1 * student_t_lccdf(0 | 3, 0, 2.5);
}
```
7. ... 
8. ... 
9. ... 

```default
model {
  // likelihood including constants
  if (!prior_only) {
    // initialize linear predictor term
    vector[N] mu = rep_vector(0.0, N);
    mu += Intercept;
    for (n in 1:N) {
      // add more terms to the linear predictor
      mu[n] += r_1_1[J_1[n]] * Z_1_1[n];          # <10> 
    }
    target += normal_lpdf(Y | mu, sigma);
  }
  // priors including constants
  target += lprior;
  target += std_normal_lpdf(z_1[1]);              # <11> 
}
```
10. ... 
11. They are doing some standardized tricks here ... 

--- 

If you do `summary(m2)` then it becomes 

```
Multilevel Hyperparameters:
~PID (Number of levels: 50) 
              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
sd(Intercept)     1.04      0.11     0.85     1.29 1.01      335      781

Regression Coefficients:
          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
Intercept     5.23      0.14     4.96     5.50 1.03      167      362

Further Distributional Parameters:
      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
sigma     0.91      0.02     0.87     0.95 1.00     2990     2879
```


<!-- # Model 3  -->

<!-- ```{r} -->
<!-- f <- bf(out ~ 1 + (1 | PID),  -->
<!--         sigma ~ 1) -->

<!-- get_prior(f, data = data) -->

<!-- m3 <- brm(f, data = data, family = gaussian) -->
<!-- ``` -->

# Model 4

```{r}
f <- bf(out ~ 1 + (1 | PID),
        sigma ~ 1 + (1 | PID))

get_prior(f, data = data)
```

```{r}
#| output: false
#| eval: false 
m4 <- brm(f, data = data, family = gaussian)
get_variables(m4)
```

`get_variables` give:

- `b_Intercept`
- `b_sigma_Intercept`
- `sd_PID__Intercept`
- `sd_PID__sigma_Intercept`
- `Intercept`
- `Intercept_sigma`
- `r_PID[num, Intercept]`
- `r_PID__sigma[num, Intercept]`

Stan code:

```{r}
#| column: margin 
make_stancode(bf(out ~ 1 + (1 | PID), 
                 sigma ~ 1 + (1 | PID)),
              data = data,
              family = gaussian)
```

Now let's break this one down: 

... 

